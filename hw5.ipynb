{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPSC 330 - Applied Machine Learning \n",
    "\n",
    "## Homework 5: Putting it all together \n",
    "### Associated lectures: All material till lecture 11\n",
    "\n",
    "**Feb 26, 11:59pm: See the [Calendar](https://github.com/UBC-CS/cpsc330-2023W2/tree/main?tab=readme-ov-file#deliverable-due-dates-tentative).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Submission instructions <a name=\"si\"></a>\n",
    "<hr>\n",
    "\n",
    "_points: 4_\n",
    "\n",
    "You will receive marks for correctly submitting this assignment. To submit this assignment, follow the instructions below:\n",
    "\n",
    "- **You may work on this assignment in a group (group size <= 4) and submit your assignment as a group.** \n",
    "- Below are some instructions on working as a group.  \n",
    "    - The maximum group size is 4.\n",
    "    - You can choose your own group members. \n",
    "    - Use group work as an opportunity to collaborate and learn new things from each other. \n",
    "    - Be respectful to each other and make sure you understand all the concepts in the assignment well. \n",
    "    - It's your responsibility to make sure that the assignment is submitted by one of the group members before the deadline. \n",
    "- Be sure to follow the [homework submission instructions](https://github.com/UBC-CS/cpsc330-2023W2/blob/main/docs/homework_instructions.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import string\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from hashlib import sha1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import tests_hw5\n",
    "from sklearn import datasets\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a name=\"in\"></a>\n",
    "\n",
    "In this homework you will be working on an open-ended mini-project, where you will put all the different things you have learned so far together to solve an interesting problem.\n",
    "\n",
    "A few notes and tips when you work on this mini-project: \n",
    "\n",
    "#### Tips\n",
    "1. This mini-project is open-ended, and while working on it, there might be some situations where you'll have to use your own judgment and make your own decisions (as you would be doing when you work as a data scientist). Make sure you explain your decisions whenever necessary. \n",
    "2. **Do not include everything you ever tried in your submission** -- it's fine just to have your final code. That said, your code should be reproducible and well-documented. For example, if you chose your hyperparameters based on some hyperparameter optimization experiment, you should leave in the code for that experiment so that someone else could re-run it and obtain the same hyperparameters, rather than mysteriously just setting the hyperparameters to some (carefully chosen) values in your code. \n",
    "3. If you realize that you are repeating a lot of code try to organize it in functions. Clear presentation of your code, experiments, and results is the key to be successful in this lab. You may use code from lecture notes or previous lab solutions with appropriate attributions. \n",
    "\n",
    "#### Assessment\n",
    "We plan to grade fairly and leniently. We don't have some secret target score that you need to achieve to get a good grade. **You'll be assessed on demonstration of mastery of course topics, clear presentation, and the quality of your analysis and results.** For example, if you just have a bunch of code and no text or figures, that's not good. If you do a bunch of sane things and get a lower accuracy than your friend, don't sweat it.\n",
    "\n",
    "\n",
    "#### A final note\n",
    "Finally, this style of this \"project\" question is different from other assignments. It'll be up to you to decide when you're \"done\" -- in fact, this is one of the hardest parts of real projects. But please don't spend WAY too much time on this... perhaps \"a few hours\". Of course if you're having fun you're welcome to spend as much time as you want! But, if so, try not to do it out of perfectionism or getting the best possible grade. Do it because you're learning and enjoying it. Students from the past cohorts have found such kind of labs useful and fun and I hope you enjoy it as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 1. Pick your problem and explain the prediction problem <a name=\"1\"></a>\n",
    "<hr>\n",
    "\n",
    "_points: 3_\n",
    "\n",
    "In this mini project, you will be working on a classification problem of predicting whether a credit card client will default or not. \n",
    "For this problem, you will use [Default of Credit Card Clients Dataset](https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset). In this data set, there are 30,000 examples and 24 features, and the goal is to estimate whether a person will default (fail to pay) their credit card bills; this column is labeled \"default.payment.next.month\" in the data. The rest of the columns can be used as features. You may take some ideas and compare your results with [the associated research paper](https://www.sciencedirect.com/science/article/pii/S0957417407006719), which is available through [the UBC library](https://www.library.ubc.ca/). \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Spend some time understanding the problem and what each feature means. You can find this information in the documentation on [the dataset page on Kaggle](https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset). Write a few sentences on your initial thoughts on the problem and the dataset. \n",
    "2. Download the dataset and read it as a pandas dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_1\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the dataset, we think that some of the columns needs to be normalized. ID should be dropped. Whether a person defaults should depend on his bill amount and potentially his credit and education level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272.0</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>3261.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331.0</td>\n",
       "      <td>14948.0</td>\n",
       "      <td>15549.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314.0</td>\n",
       "      <td>28959.0</td>\n",
       "      <td>29547.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940.0</td>\n",
       "      <td>19146.0</td>\n",
       "      <td>19131.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>36681.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>29996</td>\n",
       "      <td>220000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>88004.0</td>\n",
       "      <td>31237.0</td>\n",
       "      <td>15980.0</td>\n",
       "      <td>8500.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>5003.0</td>\n",
       "      <td>3047.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>29997</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>8979.0</td>\n",
       "      <td>5190.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1837.0</td>\n",
       "      <td>3526.0</td>\n",
       "      <td>8998.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>29998</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>20878.0</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>19357.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>29999</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>52774.0</td>\n",
       "      <td>11855.0</td>\n",
       "      <td>48944.0</td>\n",
       "      <td>85900.0</td>\n",
       "      <td>3409.0</td>\n",
       "      <td>1178.0</td>\n",
       "      <td>1926.0</td>\n",
       "      <td>52964.0</td>\n",
       "      <td>1804.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>30000</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>36535.0</td>\n",
       "      <td>32428.0</td>\n",
       "      <td>15313.0</td>\n",
       "      <td>2078.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30000 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  \\\n",
       "0          1    20000.0    2          2         1   24      2      2     -1   \n",
       "1          2   120000.0    2          2         2   26     -1      2      0   \n",
       "2          3    90000.0    2          2         2   34      0      0      0   \n",
       "3          4    50000.0    2          2         1   37      0      0      0   \n",
       "4          5    50000.0    1          2         1   57     -1      0     -1   \n",
       "...      ...        ...  ...        ...       ...  ...    ...    ...    ...   \n",
       "29995  29996   220000.0    1          3         1   39      0      0      0   \n",
       "29996  29997   150000.0    1          3         2   43     -1     -1     -1   \n",
       "29997  29998    30000.0    1          2         2   37      4      3      2   \n",
       "29998  29999    80000.0    1          3         1   41      1     -1      0   \n",
       "29999  30000    50000.0    1          2         1   46      0      0      0   \n",
       "\n",
       "       PAY_4  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  \\\n",
       "0         -1  ...        0.0        0.0        0.0       0.0     689.0   \n",
       "1          0  ...     3272.0     3455.0     3261.0       0.0    1000.0   \n",
       "2          0  ...    14331.0    14948.0    15549.0    1518.0    1500.0   \n",
       "3          0  ...    28314.0    28959.0    29547.0    2000.0    2019.0   \n",
       "4          0  ...    20940.0    19146.0    19131.0    2000.0   36681.0   \n",
       "...      ...  ...        ...        ...        ...       ...       ...   \n",
       "29995      0  ...    88004.0    31237.0    15980.0    8500.0   20000.0   \n",
       "29996     -1  ...     8979.0     5190.0        0.0    1837.0    3526.0   \n",
       "29997     -1  ...    20878.0    20582.0    19357.0       0.0       0.0   \n",
       "29998      0  ...    52774.0    11855.0    48944.0   85900.0    3409.0   \n",
       "29999      0  ...    36535.0    32428.0    15313.0    2078.0    1800.0   \n",
       "\n",
       "       PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n",
       "0           0.0       0.0       0.0       0.0                           1  \n",
       "1        1000.0    1000.0       0.0    2000.0                           1  \n",
       "2        1000.0    1000.0    1000.0    5000.0                           0  \n",
       "3        1200.0    1100.0    1069.0    1000.0                           0  \n",
       "4       10000.0    9000.0     689.0     679.0                           0  \n",
       "...         ...       ...       ...       ...                         ...  \n",
       "29995    5003.0    3047.0    5000.0    1000.0                           0  \n",
       "29996    8998.0     129.0       0.0       0.0                           0  \n",
       "29997   22000.0    4200.0    2000.0    3100.0                           1  \n",
       "29998    1178.0    1926.0   52964.0    1804.0                           1  \n",
       "29999    1430.0    1000.0    1000.0    1000.0                           1  \n",
       "\n",
       "[30000 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"./data/UCI_Credit_Card.csv\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 2. Data splitting <a name=\"2\"></a>\n",
    "<hr>\n",
    "\n",
    "_points: 2_\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Split the data into train (70%) and test (30%) portions with `random_state=76`.\n",
    "\n",
    "> If your computer cannot handle training on 70% training data, make the test split bigger.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_2\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(dataset, random_state=76, test_size=0.3)\n",
    "\n",
    "X = dataset.drop(columns=[\"default.payment.next.month\"])\n",
    "y = dataset[\"default.payment.next.month\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=76\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 3. EDA <a name=\"3\"></a>\n",
    "<hr>\n",
    "\n",
    "_points: 10_\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Perform exploratory data analysis on the train set.\n",
    "2. Include at least two summary statistics and two visualizations that you find useful, and accompany each one with a sentence explaining it.\n",
    "3. Summarize your initial observations about the data. \n",
    "4. Pick appropriate metric/metrics for assessment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_3\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                            0\n",
      "LIMIT_BAL                     0\n",
      "SEX                           0\n",
      "EDUCATION                     0\n",
      "MARRIAGE                      0\n",
      "AGE                           0\n",
      "PAY_0                         0\n",
      "PAY_2                         0\n",
      "PAY_3                         0\n",
      "PAY_4                         0\n",
      "PAY_5                         0\n",
      "PAY_6                         0\n",
      "BILL_AMT1                     0\n",
      "BILL_AMT2                     0\n",
      "BILL_AMT3                     0\n",
      "BILL_AMT4                     0\n",
      "BILL_AMT5                     0\n",
      "BILL_AMT6                     0\n",
      "PAY_AMT1                      0\n",
      "PAY_AMT2                      0\n",
      "PAY_AMT3                      0\n",
      "PAY_AMT4                      0\n",
      "PAY_AMT5                      0\n",
      "PAY_AMT6                      0\n",
      "default.payment.next.month    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missingValue = train_df.apply(lambda x: sum(x.isna()))\n",
    "print(missingValue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing values in any of the variables, so we won't need to use imputation for data preprocessing later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>2.100000e+04</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "      <td>21000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15011.587619</td>\n",
       "      <td>167563.508571</td>\n",
       "      <td>1.604381</td>\n",
       "      <td>1.843905</td>\n",
       "      <td>1.554667</td>\n",
       "      <td>35.412952</td>\n",
       "      <td>-0.012190</td>\n",
       "      <td>-0.132714</td>\n",
       "      <td>-0.168333</td>\n",
       "      <td>-0.223143</td>\n",
       "      <td>...</td>\n",
       "      <td>43039.813952</td>\n",
       "      <td>40121.889810</td>\n",
       "      <td>38623.497095</td>\n",
       "      <td>5601.265286</td>\n",
       "      <td>6.059441e+03</td>\n",
       "      <td>5204.302571</td>\n",
       "      <td>4889.281333</td>\n",
       "      <td>4782.900857</td>\n",
       "      <td>5162.918714</td>\n",
       "      <td>0.221857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8658.232639</td>\n",
       "      <td>129919.112502</td>\n",
       "      <td>0.488995</td>\n",
       "      <td>0.789845</td>\n",
       "      <td>0.521970</td>\n",
       "      <td>9.136302</td>\n",
       "      <td>1.121864</td>\n",
       "      <td>1.196554</td>\n",
       "      <td>1.195375</td>\n",
       "      <td>1.165490</td>\n",
       "      <td>...</td>\n",
       "      <td>63817.414980</td>\n",
       "      <td>60400.798292</td>\n",
       "      <td>59055.005208</td>\n",
       "      <td>16239.423781</td>\n",
       "      <td>2.407470e+04</td>\n",
       "      <td>16865.645456</td>\n",
       "      <td>16486.840852</td>\n",
       "      <td>15431.523094</td>\n",
       "      <td>17170.608569</td>\n",
       "      <td>0.415505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-170000.000000</td>\n",
       "      <td>-81334.000000</td>\n",
       "      <td>-209051.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7493.750000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2300.000000</td>\n",
       "      <td>1800.000000</td>\n",
       "      <td>1266.250000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>8.200000e+02</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>257.750000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15041.000000</td>\n",
       "      <td>140000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>18990.000000</td>\n",
       "      <td>18091.000000</td>\n",
       "      <td>17127.000000</td>\n",
       "      <td>2112.500000</td>\n",
       "      <td>2.009000e+03</td>\n",
       "      <td>1801.500000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22505.750000</td>\n",
       "      <td>240000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>54740.000000</td>\n",
       "      <td>50065.250000</td>\n",
       "      <td>48950.500000</td>\n",
       "      <td>5012.000000</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>4531.250000</td>\n",
       "      <td>4048.500000</td>\n",
       "      <td>4078.000000</td>\n",
       "      <td>4001.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>29999.000000</td>\n",
       "      <td>800000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>706864.000000</td>\n",
       "      <td>823540.000000</td>\n",
       "      <td>568638.000000</td>\n",
       "      <td>873552.000000</td>\n",
       "      <td>1.684259e+06</td>\n",
       "      <td>889043.000000</td>\n",
       "      <td>621000.000000</td>\n",
       "      <td>426529.000000</td>\n",
       "      <td>528666.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID      LIMIT_BAL           SEX     EDUCATION      MARRIAGE  \\\n",
       "count  21000.000000   21000.000000  21000.000000  21000.000000  21000.000000   \n",
       "mean   15011.587619  167563.508571      1.604381      1.843905      1.554667   \n",
       "std     8658.232639  129919.112502      0.488995      0.789845      0.521970   \n",
       "min        1.000000   10000.000000      1.000000      0.000000      0.000000   \n",
       "25%     7493.750000   50000.000000      1.000000      1.000000      1.000000   \n",
       "50%    15041.000000  140000.000000      2.000000      2.000000      2.000000   \n",
       "75%    22505.750000  240000.000000      2.000000      2.000000      2.000000   \n",
       "max    29999.000000  800000.000000      2.000000      6.000000      3.000000   \n",
       "\n",
       "                AGE         PAY_0         PAY_2         PAY_3         PAY_4  \\\n",
       "count  21000.000000  21000.000000  21000.000000  21000.000000  21000.000000   \n",
       "mean      35.412952     -0.012190     -0.132714     -0.168333     -0.223143   \n",
       "std        9.136302      1.121864      1.196554      1.195375      1.165490   \n",
       "min       21.000000     -2.000000     -2.000000     -2.000000     -2.000000   \n",
       "25%       28.000000     -1.000000     -1.000000     -1.000000     -1.000000   \n",
       "50%       34.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%       41.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max       79.000000      8.000000      8.000000      8.000000      8.000000   \n",
       "\n",
       "       ...      BILL_AMT4      BILL_AMT5      BILL_AMT6       PAY_AMT1  \\\n",
       "count  ...   21000.000000   21000.000000   21000.000000   21000.000000   \n",
       "mean   ...   43039.813952   40121.889810   38623.497095    5601.265286   \n",
       "std    ...   63817.414980   60400.798292   59055.005208   16239.423781   \n",
       "min    ... -170000.000000  -81334.000000 -209051.000000       0.000000   \n",
       "25%    ...    2300.000000    1800.000000    1266.250000    1000.000000   \n",
       "50%    ...   18990.000000   18091.000000   17127.000000    2112.500000   \n",
       "75%    ...   54740.000000   50065.250000   48950.500000    5012.000000   \n",
       "max    ...  706864.000000  823540.000000  568638.000000  873552.000000   \n",
       "\n",
       "           PAY_AMT2       PAY_AMT3       PAY_AMT4       PAY_AMT5  \\\n",
       "count  2.100000e+04   21000.000000   21000.000000   21000.000000   \n",
       "mean   6.059441e+03    5204.302571    4889.281333    4782.900857   \n",
       "std    2.407470e+04   16865.645456   16486.840852   15431.523094   \n",
       "min    0.000000e+00       0.000000       0.000000       0.000000   \n",
       "25%    8.200000e+02     390.000000     291.000000     257.750000   \n",
       "50%    2.009000e+03    1801.500000    1500.000000    1500.000000   \n",
       "75%    5.000000e+03    4531.250000    4048.500000    4078.000000   \n",
       "max    1.684259e+06  889043.000000  621000.000000  426529.000000   \n",
       "\n",
       "            PAY_AMT6  default.payment.next.month  \n",
       "count   21000.000000                21000.000000  \n",
       "mean     5162.918714                    0.221857  \n",
       "std     17170.608569                    0.415505  \n",
       "min         0.000000                    0.000000  \n",
       "25%       150.000000                    0.000000  \n",
       "50%      1500.000000                    0.000000  \n",
       "75%      4001.000000                    0.000000  \n",
       "max    528666.000000                    1.000000  \n",
       "\n",
       "[8 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The range for each variable from BILL_AMT1 to BILL_AMT6 and PAY_AMT1 to PAY_AMT6 is quite large in which there is a significant difference between the minimum and maximum values, which indicates the need for scaling these variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, -1,  2,  1, -2,  3,  4,  5,  8,  6,  7], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"PAY_0\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 3, 0], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"MARRIAGE\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 5, 4, 6, 0], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"EDUCATION\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAHFCAYAAAAT5Oa6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABIGElEQVR4nO3dfVhUdf7/8dfEnUA4igbIikqJRmJ3siF2o6biTd6UlZZJlqaWppK6luuvlcogtdDKNDVDzbtuNWs3FMtsTcmbotI17cZSE0QLB+8CxPP7o4vzbRxURGBGzvNxXeda53Pec877nHbXV5/5nBmbYRiGAAAALOwSdzcAAADgbgQiAABgeQQiAABgeQQiAABgeQQiAABgeQQiAABgeQQiAABgeQQiAABgeQQiAABgeQQioBrMnz9fNptNW7ZsKXN/9+7d1aRJE6exJk2a6IEHHjiv82zYsEHJyck6fPhwxRq1oDfffFMtWrSQv7+/bDabsrOzy6z79NNPZbPZzrjNnz/frG3Xrp05fskllygoKEhNmzbV3XffrXfeeUenTp1yOb7NZtOjjz5a5rnfeecd2Ww2ffrppy77PvjgA/Xo0UOhoaHy9fVVcHCwOnTooMWLF6u4uNil/tChQ/Lz83P572NycvJZr690a9eunSTpgQce0KWXXupy/OLiYs2aNUvx8fGy2+3y9/dXdHS0nnjiCf32228u9aX3qkuXLi77fv75Z9lsNj3//PNl3hegMnm7uwEAZVu+fLlq1659Xu/ZsGGDnnrqKT3wwAOqU6dO1TRWgxw8eFCJiYnq0qWLZs6cKT8/PzVr1uys70lJSVH79u1dxq+44gqn15dffrkWL14sSTp27Jh2796tFStW6O6779bNN9+sDz74QHa7vcK9G4ahgQMHav78+erWrZvS0tIUEREhh8OhtWvXatiwYTp06JBGjRrl9L433nhDRUVFkqR58+YpNjZWkvTQQw85hZKcnBz17t1bI0aMUL9+/czxs/138vjx4+rWrZvWr1+vIUOG6Mknn5S/v782btyo559/XkuWLFFmZqaaN2/u8t5Vq1bpk08+0a233lrhewJcCAIR4KGuu+46d7dw3oqLi2Wz2eTtfXH8X8uuXbtUXFys/v37q23btuV6T1RUlFq3bn3OOn9/f5e6hx56SOnp6Ro4cKCGDBmiN998s0J9S9LUqVM1f/58PfXUU/rXv/7ltK9Hjx4aN26cfvjhB5f3vf766woJCVHjxo21dOlSpaWlyd/fXw0bNlTDhg3Nup9//lmS1KhRo3JdryQ99thjWrdunZYtW6a+ffua4+3bt9ddd92lG264QXfeeae+/vpreXl5mfubNWumkydPaty4cdq8ebNsNtv53AqgUvCRGeChTv/I7NSpU5o0aZKaN28uf39/1alTR1dffbVefPFFSX9+5PGPf/xDkhQZGWl+xFH6McupU6c0ZcoUXXnllfLz81NISIjuv/9+7du3z+m8hmEoJSVFjRs3Vq1atRQbG6vMzEy1a9fO/LhE+r+PkN544w2NGTNGf/vb3+Tn56cffvhBBw8e1LBhw3TVVVfp0ksvVUhIiG699Vb997//dTpX6UciU6dO1eTJk9WkSRP5+/urXbt2Zlh54oknFB4eLrvdrjvuuEN5eXnlun8rV65UfHy8AgICFBQUpE6dOmnjxo3m/gceeEA33XSTJKlv375OHwdVpQcffFDdunXT22+/rV9++aVCxyguLtbkyZN15ZVX6sknnyyzJiwszLy+Ul988YW2bdumxMREDR48WA6HQ++++26Fejhdbm6uXn/9dXXu3NkpDJVq1qyZHn/8cW3fvl0rVqxw2ufj46Nnn31WW7duvaCQCFwIAhFQjUpKSnTy5EmXzTCMc753ypQpSk5O1r333qt///vfevPNNzVo0CBzvdBDDz2kESNGSJLee+89bdy4URs3btT1118vSXrkkUf0+OOPq1OnTlq5cqWeeeYZZWRkqE2bNjp06JB5ngkTJmjChAnq0qWL3n//fT388MN66KGHtGvXrjL7Gj9+vPbs2aNXX31VH3zwgUJCQvT7779LkiZOnKh///vfSk9P1+WXX6527dqVuQ7mlVde0eeff65XXnlFr732mr777jv16NFDgwYN0sGDB/X6669rypQpWrNmjR566KFz3qslS5aoV69eql27tpYuXap58+YpPz9f7dq10/r16yVJTz75pF555RVJf34MtnHjRs2cOfOcxz516lSZ/wzPR8+ePWUYhktALK8tW7bo999/V69evc5rNmXevHmSpIEDB+qee+5RQECAOXah1q5dq5MnT+r2228/Y03pvszMTJd9ffv2VatWrfT//t//K3PtE1DVLo55baCGONtHD40bNz7rez///HO1bNlSycnJ5ljnzp3NPzds2FCNGjWS9OfHbX9dpP3dd99pzpw5GjZsmF5++WVz/LrrrlNcXJymTZumZ599Vvn5+UpLS1Pfvn01e/Zssy4mJkbx8fFlrq+54oor9PbbbzuNBQcHO4WLkpISde7cWT///LNeeukll5mYOnXqaMWKFbrkkj//He3QoUNKSkrSlVdeqffff9/pOqZPn66CgoIzrmU5deqU/vGPf6hly5b66KOPzGN269ZNV1xxhR5//HF9/vnnuuKKK3TVVVdJKv/HYJLKnP2QpL179zp95HQ2pf+s9+/fX6760+3Zs0fSnzOB5XX8+HG9+eabat26tXndd999txYuXKgff/zRZQ1UVfRUuq+09q9sNpsmT56sjh07avbs2WdcYA5UFWaIgGq0cOFCbd682WU7/aONstxwww36+uuvNWzYMK1atUoFBQXlPu/atWslyeWptRtuuEHR0dH6+OOPJUlZWVkqLCxUnz59nOpat27t8hRcqTvvvLPM8VdffVXXX3+9atWqJW9vb/n4+Ojjjz/Wjh07XGq7detmBhdJio6OliTddtttTnWl42X9hVpq586d2r9/vxITE52Oeemll+rOO+9UVlaWjh8/fsb3n8vkyZPL/GcYGhpa7mOUZ0awsr311lsqKCjQwIEDzbGBAwfKMAylp6dXay9nmtXq0KGDEhIS9PTTT+vIkSPV2hNAIAKqUXR0tGJjY1228jxtNH78eD3//PPKyspS165dVa9ePXXo0OGMj/L/Venjzg0aNHDZFx4ebu4v/c+y/nI/01/4ZR0zLS1NjzzyiOLi4vTuu+8qKytLmzdvVpcuXXTixAmX+uDgYKfXvr6+Zx3/448/yuzlr9dwpms9deqU8vPzz/j+c7n88svL/Gfo4+NT7mOUrh0KDw83x7y8vFRSUlJmfelHcqXnKJ0J3L17d7nPOW/ePNWqVUtdunTR4cOHdfjwYV199dVq0qSJ5s+ff8Zzl1d5eirdFxERccaayZMn69ChQzxqj2pHIAIuEt7e3ho9erS+/PJL/f7771q6dKn27t2rzp07n3PGo169epL+fJT6dPv371f9+vWd6g4cOOBSl5ubW+axy/q3/UWLFqldu3aaNWuWbrvtNsXFxSk2NrZa/q3/XNd6ySWXqG7dulXex9msXLlSNptNt9xyizkWGhqqX3/9tcz60vHSUBobG6vg4GC9//775Zpt2rVrl9avX68//vhDjRo1Ut26dc3t559/1q+//qpVq1Zd0DW1b99e3t7eLgum/6p0X6dOnc5Yc+211+ree+9VWlpamf89BKoKgQi4CNWpU0d33XWXhg8frt9//918RNrPz0+SXGZhSr/bZdGiRU7jmzdv1o4dO9ShQwdJUlxcnPz8/Fye9MnKyjqvJ6JsNpvZS6lvvvnG6SmvqtK8eXP97W9/05IlS5zCwrFjx/Tuu++aT565S3p6uj766CPde++95qyKJHXs2FFr167VwYMHneoNw9Dbb7+tJk2aqGnTppL+nCl6/PHH9d133+mZZ54p8zx5eXn6/PPPJf3fYuq5c+dq7dq1Ttt//vMf+fj46PXXX7+g6woLC9PAgQO1atWqMp8U27VrlyZPnqwWLVqcdeG1JE2aNElFRUV66qmnLqgn4HywqBq4SPTo0UMxMTGKjY3VZZddpl9++UXTp09X48aNFRUVJUlq2bKlJOnFF1/UgAED5OPjo+bNm6t58+YaMmSIXn75ZV1yySXq2rWrfv75Zz355JOKiIjQY489JunPj6hGjx6t1NRU1a1bV3fccYf27dunp556Sg0aNHBak3M23bt31zPPPKOJEyeqbdu22rlzp55++mlFRkae9xNZ5+uSSy7RlClTdN9996l79+4aOnSoCgsLNXXqVB0+fFjPPffcBR3/+++/V1ZWlsv46d/jc+LECbPuxIkT+umnn7RixQp9+OGHatu2rV599VWn9//rX//SBx98oLi4OD3xxBOKiopSbm6u5s6dq82bN+utt95yqv/HP/6hHTt2aOLEidq0aZP69etnfjHjZ599pjlz5uipp55SXFycFi5cqOjo6DM+odejRw+tXLlSBw8e1GWXXVbhe5OWlqadO3eqf//++uyzz9SjRw/5+fkpKytLzz//vIKCgvTuu+86fQdRWSIjI/XII4+YXykBVAsDQJVLT083JBmbN28uc/9tt91mNG7c2GmscePGxoABA8zXL7zwgtGmTRujfv36hq+vr9GoUSNj0KBBxs8//+z0vvHjxxvh4eHGJZdcYkgy1q5daxiGYZSUlBiTJ082mjVrZvj4+Bj169c3+vfvb+zdu9fp/adOnTImTZpkNGzY0PD19TWuvvpq48MPPzSuueYa44477jDr1q5da0gy3n77bZfrKSwsNMaOHWv87W9/M2rVqmVcf/31xooVK4wBAwY4Xefu3bsNScbUqVOd3n+mY5/rPv7VihUrjLi4OKNWrVpGYGCg0aFDB+Pzzz8v13nKUlp7pm3ChAlmbdu2bZ32BQYGGpdffrlx1113GW+//bZRUlJS5jm+//57o3///kaDBg0Mb29vo06dOkZCQoLx8ccfn7Gv999/37jtttuMyy67zPD29jbq1q1rtG/f3nj11VeNwsJCY8WKFYYkY/r06Wc8RkZGhiHJeOGFF8yxM/2zKTVgwAAjMDDQZbyoqMh45ZVXjLi4OOPSSy81/Pz8jObNmxvjxo0zDh065FLftm1bo0WLFi7jBw8eNGrXrn3WHoDKZDMMNzzuAOCisnv3bl155ZWaOHGi/vnPf7q7HQCodAQiAE6+/vprLV26VG3atFHt2rW1c+dOTZkyRQUFBdq2bdt5PV4OABcL1hABcBIYGKgtW7Zo3rx5Onz4sOx2u9q1a6dnn32WMASgxmKGCAAAWB6P3QMAAMsjEAEAAMsjEAEAAMtjUXU5nTp1Svv371dQUNAZf5gQAAB4FsMwdOTIEYWHh5/1y2UJROW0f//+s/4gIQAA8Fx79+51+jb50xGIyikoKEjSnze0du3abu4GAACUR0FBgSIiIsy/x8+EQFROpR+T1a5dm0AEAMBF5lzLXVhUDQAALI9ABAAALI9ABAAALI81RAAA1HAlJSUqLi52dxtVwsfHR15eXhd8HAIRAAA1lGEYys3N1eHDh93dSpWqU6eOwsLCLuh7AglEAADUUKVhKCQkRAEBATXui4UNw9Dx48eVl5cnSWrQoEGFj0UgAgCgBiopKTHDUL169dzdTpXx9/eXJOXl5SkkJKTCH5+xqBoAgBqodM1QQECAmzupeqXXeCHrpAhEAADUYDXtY7KyVMY1EogAAIDlEYgAAIDlsagaAACLmZa5q9rO9VinZhV638yZMzV16lTl5OSoRYsWmj59um6++eZK7u7/MEMEAAA8yptvvqmkpCRNmDBBX331lW6++WZ17dpVe/bsqbJzEogAAIBHSUtL06BBg/TQQw8pOjpa06dPV0REhGbNmlVl5yQQAQAAj1FUVKStW7cqISHBaTwhIUEbNmyosvOyhgioASprPUBFP+sHgMpy6NAhlZSUKDQ01Gk8NDRUubm5VXZeZogAAIDHOf27hQzDqNLvVCIQAQAAj1G/fn15eXm5zAbl5eW5zBpVJgIRAADwGL6+vmrVqpUyMzOdxjMzM9WmTZsqOy9riAAAgEcZPXq0EhMTFRsbq/j4eM2ZM0d79uzRww8/XGXnJBABAACP0rdvX/322296+umnlZOTo5iYGP3nP/9R48aNq+ycBCIAACzmYniidNiwYRo2bFi1nY81RAAAwPIIRAAAwPIIRAAAwPIIRAAAwPIIRAAAwPIIRAAAwPIIRAAAwPIIRAAAwPIIRAAAwPIIRAAAwPLc+tMdTZo00S+//OIyPmzYML3yyisyDENPPfWU5syZo/z8fMXFxemVV15RixYtzNrCwkKNHTtWS5cu1YkTJ9ShQwfNnDlTDRs2NGvy8/M1cuRIrVy5UpLUs2dPvfzyy6pTp06VXyMAAB5nbWr1nav9+PN+y2effaapU6dq69atysnJ0fLly3X77bdXfm9/4dYZos2bNysnJ8fcMjMzJUl33323JGnKlClKS0vTjBkztHnzZoWFhalTp046cuSIeYykpCQtX75cy5Yt0/r163X06FF1795dJSUlZk2/fv2UnZ2tjIwMZWRkKDs7W4mJidV7sQAAoFyOHTuma665RjNmzKi2c7p1huiyyy5zev3cc8/piiuuUNu2bWUYhqZPn64JEyaod+/ekqQFCxYoNDRUS5Ys0dChQ+VwODRv3jy98cYb6tixoyRp0aJFioiI0Jo1a9S5c2ft2LFDGRkZysrKUlxcnCRp7ty5io+P186dO9W8efPqvWgAAHBWXbt2VdeuXav1nB6zhqioqEiLFi3SwIEDZbPZtHv3buXm5iohIcGs8fPzU9u2bbVhwwZJ0tatW1VcXOxUEx4erpiYGLNm48aNstvtZhiSpNatW8tut5s1ZSksLFRBQYHTBgAAaiaPCUQrVqzQ4cOH9cADD0iScnNzJUmhoaFOdaGhoea+3Nxc+fr6qm7dumetCQkJcTlfSEiIWVOW1NRU2e12c4uIiKjwtQEAAM/mMYFo3rx56tq1q8LDw53GbTab02vDMFzGTnd6TVn15zrO+PHj5XA4zG3v3r3luQwAAHAR8ohA9Msvv2jNmjV66KGHzLGwsDBJcpnFycvLM2eNwsLCVFRUpPz8/LPWHDhwwOWcBw8edJl9+is/Pz/Vrl3baQMAADWTRwSi9PR0hYSE6LbbbjPHIiMjFRYWZj55Jv25zmjdunVq06aNJKlVq1by8fFxqsnJydG2bdvMmvj4eDkcDm3atMms+eKLL+RwOMwaAABgbW59ykySTp06pfT0dA0YMEDe3v/Xjs1mU1JSklJSUhQVFaWoqCilpKQoICBA/fr1kyTZ7XYNGjRIY8aMUb169RQcHKyxY8eqZcuW5lNn0dHR6tKliwYPHqzZs2dLkoYMGaLu3bvzhBkAAB7o6NGj+uGHH8zXu3fvVnZ2toKDg9WoUaMqOafbA9GaNWu0Z88eDRw40GXfuHHjdOLECQ0bNsz8YsbVq1crKCjIrJk2bZq8vb3Vp08f84sZ58+fLy8vL7Nm8eLFGjlypPk0Ws+ePav1uw0AAED5bdmyRe3btzdfjx49WpI0YMAAzZ8/v0rOaTMMw6iSI9cwBQUFstvtcjgcrCeCx5mWuatSjvNYp2aVchwA7vfHH39o9+7dioyMVK1atdzdTpU627WW9+9vj1hDBAAA4E4EIgAAYHkEIgAAYHkEIgAAYHkEIgAAajArPDtVGddIIAIAoAby8fGRJB0/ftzNnVS90mssveaKcPv3EAEAgMrn5eWlOnXqKC8vT5IUEBBwzt8CvdgYhqHjx48rLy9PderUcfoOwvNFIAIAoIYq/V3Q0lBUU9WpU8e81ooiEAEAUEPZbDY1aNBAISEhKi4udnc7VcLHx+eCZoZKEYgAAKjhvLy8KiU01GQsqgYAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJZHIAIAAJbn9kD066+/qn///qpXr54CAgJ07bXXauvWreZ+wzCUnJys8PBw+fv7q127dtq+fbvTMQoLCzVixAjVr19fgYGB6tmzp/bt2+dUk5+fr8TERNntdtntdiUmJurw4cPVcYkAAMDDebvz5Pn5+brxxhvVvn17ffTRRwoJCdGPP/6oOnXqmDVTpkxRWlqa5s+fr2bNmmnSpEnq1KmTdu7cqaCgIElSUlKSPvjgAy1btkz16tXTmDFj1L17d23dulVeXl6SpH79+mnfvn3KyMiQJA0ZMkSJiYn64IMPqv26cX6mZe6qtGM91qlZpR0LAFBzuDUQTZ48WREREUpPTzfHmjRpYv7ZMAxNnz5dEyZMUO/evSVJCxYsUGhoqJYsWaKhQ4fK4XBo3rx5euONN9SxY0dJ0qJFixQREaE1a9aoc+fO2rFjhzIyMpSVlaW4uDhJ0ty5cxUfH6+dO3eqefPm1XfRAADA47j1I7OVK1cqNjZWd999t0JCQnTddddp7ty55v7du3crNzdXCQkJ5pifn5/atm2rDRs2SJK2bt2q4uJip5rw8HDFxMSYNRs3bpTdbjfDkCS1bt1adrvdrDldYWGhCgoKnDYAAFAzuTUQ/fTTT5o1a5aioqK0atUqPfzwwxo5cqQWLlwoScrNzZUkhYaGOr0vNDTU3JebmytfX1/VrVv3rDUhISEu5w8JCTFrTpeammquN7Lb7YqIiLiwiwUAAB7LrYHo1KlTuv7665WSkqLrrrtOQ4cO1eDBgzVr1iynOpvN5vTaMAyXsdOdXlNW/dmOM378eDkcDnPbu3dveS8LAABcZNwaiBo0aKCrrrrKaSw6Olp79uyRJIWFhUmSyyxOXl6eOWsUFhamoqIi5efnn7XmwIEDLuc/ePCgy+xTKT8/P9WuXdtpAwAANZNbA9GNN96onTt3Oo3t2rVLjRs3liRFRkYqLCxMmZmZ5v6ioiKtW7dObdq0kSS1atVKPj4+TjU5OTnatm2bWRMfHy+Hw6FNmzaZNV988YUcDodZAwAArMutT5k99thjatOmjVJSUtSnTx9t2rRJc+bM0Zw5cyT9+TFXUlKSUlJSFBUVpaioKKWkpCggIED9+vWTJNntdg0aNEhjxoxRvXr1FBwcrLFjx6ply5bmU2fR0dHq0qWLBg8erNmzZ0v687H77t2784QZAABwbyD6+9//ruXLl2v8+PF6+umnFRkZqenTp+u+++4za8aNG6cTJ05o2LBhys/PV1xcnFavXm1+B5EkTZs2Td7e3urTp49OnDihDh06aP78+eZ3EEnS4sWLNXLkSPNptJ49e2rGjBnVd7EAAMBj2QzDMNzdxMWgoKBAdrtdDoeD9UTVjC9mPLfKukc19f4AsK7y/v3t9p/uAAAAcDcCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDwCEQAAsDy3BqLk5GTZbDanLSwszNxvGIaSk5MVHh4uf39/tWvXTtu3b3c6RmFhoUaMGKH69esrMDBQPXv21L59+5xq8vPzlZiYKLvdLrvdrsTERB0+fLg6LhEAAFwE3D5D1KJFC+Xk5Jjbt99+a+6bMmWK0tLSNGPGDG3evFlhYWHq1KmTjhw5YtYkJSVp+fLlWrZsmdavX6+jR4+qe/fuKikpMWv69eun7OxsZWRkKCMjQ9nZ2UpMTKzW6wQAAJ7L2+0NeHs7zQqVMgxD06dP14QJE9S7d29J0oIFCxQaGqolS5Zo6NChcjgcmjdvnt544w117NhRkrRo0SJFRERozZo16ty5s3bs2KGMjAxlZWUpLi5OkjR37lzFx8dr586dat68efVdLAAA8EhunyH6/vvvFR4ersjISN1zzz366aefJEm7d+9Wbm6uEhISzFo/Pz+1bdtWGzZskCRt3bpVxcXFTjXh4eGKiYkxazZu3Ci73W6GIUlq3bq17Ha7WVOWwsJCFRQUOG0AAKBmcmsgiouL08KFC7Vq1SrNnTtXubm5atOmjX777Tfl5uZKkkJDQ53eExoaau7Lzc2Vr6+v6tate9aakJAQl3OHhISYNWVJTU011xzZ7XZFRERc0LUCAADP5dZA1LVrV915551q2bKlOnbsqH//+9+S/vxorJTNZnN6j2EYLmOnO72mrPpzHWf8+PFyOBzmtnfv3nJdEwAAuPi4/SOzvwoMDFTLli31/fffm+uKTp/FycvLM2eNwsLCVFRUpPz8/LPWHDhwwOVcBw8edJl9+is/Pz/Vrl3baQMAADWTRwWiwsJC7dixQw0aNFBkZKTCwsKUmZlp7i8qKtK6devUpk0bSVKrVq3k4+PjVJOTk6Nt27aZNfHx8XI4HNq0aZNZ88UXX8jhcJg1AADA2tz6lNnYsWPVo0cPNWrUSHl5eZo0aZIKCgo0YMAA2Ww2JSUlKSUlRVFRUYqKilJKSooCAgLUr18/SZLdbtegQYM0ZswY1atXT8HBwRo7dqz5EZwkRUdHq0uXLho8eLBmz54tSRoyZIi6d+/OE2YAAECSmwPRvn37dO+99+rQoUO67LLL1Lp1a2VlZalx48aSpHHjxunEiRMaNmyY8vPzFRcXp9WrVysoKMg8xrRp0+Tt7a0+ffroxIkT6tChg+bPny8vLy+zZvHixRo5cqT5NFrPnj01Y8aM6r1YAADgsWyGYRjubuJiUFBQILvdLofDwXqiajYtc1elHeuxTs0q7ViepLLuUU29PwCsq7x/f3vUGiIAAAB3IBABAADLIxABAADLIxABAADLIxABAADLIxABAADLIxABAADLIxABAADLIxABAADLIxABAADLIxABAADLIxABAADLq1Ag2r17d2X3AQAA4DYVCkRNmzZV+/bttWjRIv3xxx+V3RMAAEC1qlAg+vrrr3XddddpzJgxCgsL09ChQ7Vp06bK7g0AAKBaVCgQxcTEKC0tTb/++qvS09OVm5urm266SS1atFBaWpoOHjxY2X0CAABUmQtaVO3t7a077rhDb731liZPnqwff/xRY8eOVcOGDXX//fcrJyensvoEAACoMhcUiLZs2aJhw4apQYMGSktL09ixY/Xjjz/qk08+0a+//qpevXpVVp8AAABVxrsib0pLS1N6erp27typbt26aeHCherWrZsuueTPfBUZGanZs2fryiuvrNRmAQAAqkKFAtGsWbM0cOBAPfjggwoLCyuzplGjRpo3b94FNQcAAFAdKhSIvv/++3PW+Pr6asCAARU5PAAAQLWq0Bqi9PR0vf322y7jb7/9thYsWHDBTQEAAFSnCgWi5557TvXr13cZDwkJUUpKygU3BQAAUJ0qFIh++eUXRUZGuow3btxYe/bsueCmAAAAqlOFAlFISIi++eYbl/Gvv/5a9erVu+CmAAAAqlOFAtE999yjkSNHau3atSopKVFJSYk++eQTjRo1Svfcc09l9wgAAFClKvSU2aRJk/TLL7+oQ4cO8vb+8xCnTp3S/fffzxoiAABw0alQIPL19dWbb76pZ555Rl9//bX8/f3VsmVLNW7cuLL7AwAAqHIVCkSlmjVrpmbNmlVWLwAAAG5RoUBUUlKi+fPn6+OPP1ZeXp5OnTrltP+TTz6plOYAAACqQ4UC0ahRozR//nzddtttiomJkc1mq+y+AAAAqk2FAtGyZcv01ltvqVu3bpXdDwAAQLWr0GP3vr6+atq0aWX3AgAA4BYVCkRjxozRiy++KMMwKrsfAACAalehj8zWr1+vtWvX6qOPPlKLFi3k4+PjtP+9996rlOYAAACqQ4UCUZ06dXTHHXdUdi8AAABuUaGPzNLT08+6VURqaqpsNpuSkpLMMcMwlJycrPDwcPn7+6tdu3bavn270/sKCws1YsQI1a9fX4GBgerZs6f27dvnVJOfn6/ExETZ7XbZ7XYlJibq8OHDFeoTAADUPBUKRJJ08uRJrVmzRrNnz9aRI0ckSfv379fRo0fP+1ibN2/WnDlzdPXVVzuNT5kyRWlpaZoxY4Y2b96ssLAwderUyTyfJCUlJWn58uVatmyZ1q9fr6NHj6p79+4qKSkxa/r166fs7GxlZGQoIyND2dnZSkxMrOCVAwCAmqZCgeiXX35Ry5Yt1atXLw0fPlwHDx6U9GeAGTt27Hkd6+jRo7rvvvs0d+5c1a1b1xw3DEPTp0/XhAkT1Lt3b8XExGjBggU6fvy4lixZIklyOByaN2+eXnjhBXXs2FHXXXedFi1apG+//VZr1qyRJO3YsUMZGRl67bXXFB8fr/j4eM2dO1cffvihdu7cWZHLBwAANUyFAtGoUaMUGxur/Px8+fv7m+N33HGHPv744/M61vDhw3XbbbepY8eOTuO7d+9Wbm6uEhISzDE/Pz+1bdtWGzZskCRt3bpVxcXFTjXh4eGKiYkxazZu3Ci73a64uDizpnXr1rLb7WYNAACwtgo/Zfb555/L19fXabxx48b69ddfy32cZcuW6csvv9TmzZtd9uXm5kqSQkNDncZDQ0P1yy+/mDW+vr5OM0ulNaXvz83NVUhIiMvxQ0JCzJqyFBYWqrCw0HxdUFBQzqsCAAAXmwrNEJ06dcppjU6pffv2KSgoqFzH2Lt3r0aNGqVFixapVq1aZ6w7/WdBDMM450+FnF5TVv25jpOammouwrbb7YqIiDjrOQEAwMWrQoGoU6dOmj59uvnaZrPp6NGjmjhxYrl/zmPr1q3Ky8tTq1at5O3tLW9vb61bt04vvfSSvL29zZmh02dx8vLyzH1hYWEqKipSfn7+WWsOHDjgcv6DBw+6zD791fjx4+VwOMxt79695bouAABw8alQIJo2bZrWrVunq666Sn/88Yf69eunJk2a6Ndff9XkyZPLdYwOHTro22+/VXZ2trnFxsbqvvvuU3Z2ti6//HKFhYUpMzPTfE9RUZHWrVunNm3aSJJatWolHx8fp5qcnBxt27bNrImPj5fD4dCmTZvMmi+++EIOh8OsKYufn59q167ttAEAgJqpQmuIwsPDlZ2draVLl+rLL7/UqVOnNGjQIN13331Oi6zPJigoSDExMU5jgYGBqlevnjmelJSklJQURUVFKSoqSikpKQoICFC/fv0kSXa7XYMGDdKYMWNUr149BQcHa+zYsWrZsqW5SDs6OlpdunTR4MGDNXv2bEnSkCFD1L17dzVv3rwilw8AAGqYCgUiSfL399fAgQM1cODAyuzHybhx43TixAkNGzZM+fn5iouL0+rVq53WKU2bNk3e3t7q06ePTpw4oQ4dOmj+/Pny8vIyaxYvXqyRI0eaT6P17NlTM2bMqLK+AQDAxcVmVOAXWhcuXHjW/ffff3+FG/JUBQUFstvtcjgcfHxWzaZl7qq0Yz3WqVmlHcuTVNY9qqn3B4B1lffv7wrNEI0aNcrpdXFxsY4fPy5fX18FBATUyEAEAABqrgotqs7Pz3fajh49qp07d+qmm27S0qVLK7tHAACAKlXh3zI7XVRUlJ577jmX2SMAAABPV2mBSJK8vLy0f//+yjwkAABAlavQGqKVK1c6vTYMQzk5OZoxY4ZuvPHGSmkMAACgulQoEN1+++1Or202my677DLdeuuteuGFFyqjLwAAgGpToUB06tSpyu4DAADAbSp1DREAAMDFqEIzRKNHjy53bVpaWkVOAQAAUG0qFIi++uorffnllzp58qT5e2C7du2Sl5eXrr/+erPOZrNVTpcAAABVqEKBqEePHgoKCtKCBQtUt25dSX9+WeODDz6om2++WWPGjKnUJgEAAKpShdYQvfDCC0pNTTXDkCTVrVtXkyZN4ikzAABw0alQICooKNCBAwdcxvPy8nTkyJELbgoAAKA6VSgQ3XHHHXrwwQf1zjvvaN++fdq3b5/eeecdDRo0SL17967sHgEAAKpUhdYQvfrqqxo7dqz69++v4uLiPw/k7a1BgwZp6tSpldogAABAVatQIAoICNDMmTM1depU/fjjjzIMQ02bNlVgYGBl9wcAAFDlLuiLGXNycpSTk6NmzZopMDBQhmFUVl8AAADVpkKB6LffflOHDh3UrFkzdevWTTk5OZKkhx56iEfuAQDARadCgeixxx6Tj4+P9uzZo4CAAHO8b9++ysjIqLTmAAAAqkOF1hCtXr1aq1atUsOGDZ3Go6Ki9Msvv1RKYwAAANWlQjNEx44dc5oZKnXo0CH5+fldcFMAAADVqUKB6JZbbtHChQvN1zabTadOndLUqVPVvn37SmsOAACgOlToI7OpU6eqXbt22rJli4qKijRu3Dht375dv//+uz7//PPK7hEAAKBKVWiG6KqrrtI333yjG264QZ06ddKxY8fUu3dvffXVV7riiisqu0cAAIAqdd4zRMXFxUpISNDs2bP11FNPVUVPAAAA1eq8Z4h8fHy0bds22Wy2qugHAACg2lXoI7P7779f8+bNq+xeAAAA3KJCi6qLior02muvKTMzU7GxsS6/YZaWllYpzQEAAFSH8wpEP/30k5o0aaJt27bp+uuvlyTt2rXLqYaP0gAAwMXmvAJRVFSUcnJytHbtWkl//lTHSy+9pNDQ0CppDgAAoDqc1xqi03/N/qOPPtKxY8cqtSEAAIDqVqFF1aVOD0gAAAAXo/MKRDabzWWNEGuGAADAxe681hAZhqEHHnjA/AHXP/74Qw8//LDLU2bvvfde5XUIAABQxc4rEA0YMMDpdf/+/Su1GQAAAHc4r0CUnp5eVX0AAAC4zQUtqgYAAKgJ3BqIZs2apauvvlq1a9dW7dq1FR8fr48++sjcbxiGkpOTFR4eLn9/f7Vr107bt293OkZhYaFGjBih+vXrKzAwUD179tS+ffucavLz85WYmCi73S673a7ExEQdPny4Oi4RAABcBNwaiBo2bKjnnntOW7Zs0ZYtW3TrrbeqV69eZuiZMmWK0tLSNGPGDG3evFlhYWHq1KmTjhw5Yh4jKSlJy5cv17Jly7R+/XodPXpU3bt3V0lJiVnTr18/ZWdnKyMjQxkZGcrOzlZiYmK1Xy8AAPBMNsPDvkwoODhYU6dO1cCBAxUeHq6kpCQ9/vjjkv6cDQoNDdXkyZM1dOhQORwOXXbZZXrjjTfUt29fSdL+/fsVERGh//znP+rcubN27Nihq666SllZWYqLi5MkZWVlKT4+Xt99952aN29err4KCgpkt9vlcDhUu3btqrl4lGla5q5zF5XTY52aVdqxPEll3aOaen8AWFd5//72mDVEJSUlWrZsmY4dO6b4+Hjt3r1bubm5SkhIMGv8/PzUtm1bbdiwQZK0detWFRcXO9WEh4crJibGrNm4caPsdrsZhiSpdevWstvtZk1ZCgsLVVBQ4LQBAICaye2B6Ntvv9Wll14qPz8/Pfzww1q+fLmuuuoq5ebmSpLL76SFhoaa+3Jzc+Xr66u6deuetSYkJMTlvCEhIWZNWVJTU801R3a7XRERERd0nQAAwHO5PRA1b95c2dnZysrK0iOPPKIBAwbof//7n7n/9G/CNgzjnN+OfXpNWfXnOs748ePlcDjMbe/eveW9JAAAcJFxeyDy9fVV06ZNFRsbq9TUVF1zzTV68cUXFRYWJkkuszh5eXnmrFFYWJiKioqUn59/1poDBw64nPfgwYMus09/5efnZz79VroBAICaye2B6HSGYaiwsFCRkZEKCwtTZmamua+oqEjr1q1TmzZtJEmtWrWSj4+PU01OTo62bdtm1sTHx8vhcGjTpk1mzRdffCGHw2HWAAAAazuvb6qubP/85z/VtWtXRURE6MiRI1q2bJk+/fRTZWRkyGazKSkpSSkpKYqKilJUVJRSUlIUEBCgfv36SZLsdrsGDRqkMWPGqF69egoODtbYsWPVsmVLdezYUZIUHR2tLl26aPDgwZo9e7YkaciQIerevXu5nzADAAA1m1sD0YEDB5SYmKicnBzZ7XZdffXVysjIUKdOnSRJ48aN04kTJzRs2DDl5+crLi5Oq1evVlBQkHmMadOmydvbW3369NGJEyfUoUMHzZ8/X15eXmbN4sWLNXLkSPNptJ49e2rGjBnVe7EAAMBjedz3EHkqvofIffgeonPje4gAoGwX3fcQAQAAuAuBCAAAWB6BCAAAWB6BCAAAWB6BCAAAWB6BCAAAWB6BCAAAWB6BCAAAWB6BCAAAWB6BCAAAWB6BCAAAWB6BCAAAWB6BCAAAWB6BCAAAWB6BCAAAWJ63uxsAgKo2LXNXpRznsU7NKuU4ADwPM0QAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDyCEQAAMDy+GJGoAZrvWfO+b1hbb3/+3P78ZXbDAB4MGaIAACA5RGIAACA5RGIAACA5RGIAACA5RGIAACA5RGIAACA5RGIAACA5RGIAACA5RGIAACA5RGIAACA5RGIAACA5bk1EKWmpurvf/+7goKCFBISottvv107d+50qjEMQ8nJyQoPD5e/v7/atWun7du3O9UUFhZqxIgRql+/vgIDA9WzZ0/t27fPqSY/P1+JiYmy2+2y2+1KTEzU4cOHq/oSAQDARcCtgWjdunUaPny4srKylJmZqZMnTyohIUHHjh0za6ZMmaK0tDTNmDFDmzdvVlhYmDp16qQjR46YNUlJSVq+fLmWLVum9evX6+jRo+revbtKSkrMmn79+ik7O1sZGRnKyMhQdna2EhMTq/V6AQCAZ3Lrr91nZGQ4vU5PT1dISIi2bt2qW265RYZhaPr06ZowYYJ69+4tSVqwYIFCQ0O1ZMkSDR06VA6HQ/PmzdMbb7yhjh07SpIWLVqkiIgIrVmzRp07d9aOHTuUkZGhrKwsxcXFSZLmzp2r+Ph47dy5U82bN6/eCwcAAB7Fo9YQORwOSVJwcLAkaffu3crNzVVCQoJZ4+fnp7Zt22rDhg2SpK1bt6q4uNipJjw8XDExMWbNxo0bZbfbzTAkSa1bt5bdbjdrTldYWKiCggKnDQAA1EweE4gMw9Do0aN10003KSYmRpKUm5srSQoNDXWqDQ0NNffl5ubK19dXdevWPWtNSEiIyzlDQkLMmtOlpqaa643sdrsiIiIu7AIBAIDH8phA9Oijj+qbb77R0qVLXfbZbDan14ZhuIyd7vSasurPdpzx48fL4XCY2969e8tzGQAA4CLkEYFoxIgRWrlypdauXauGDRua42FhYZLkMouTl5dnzhqFhYWpqKhI+fn5Z605cOCAy3kPHjzoMvtUys/PT7Vr13baAABAzeTWQGQYhh599FG99957+uSTTxQZGem0PzIyUmFhYcrMzDTHioqKtG7dOrVp00aS1KpVK/n4+DjV5OTkaNu2bWZNfHy8HA6HNm3aZNZ88cUXcjgcZg0AALAutz5lNnz4cC1ZskTvv/++goKCzJkgu90uf39/2Ww2JSUlKSUlRVFRUYqKilJKSooCAgLUr18/s3bQoEEaM2aM6tWrp+DgYI0dO1YtW7Y0nzqLjo5Wly5dNHjwYM2ePVuSNGTIEHXv3p0nzAAAgHsD0axZsyRJ7dq1cxpPT0/XAw88IEkaN26cTpw4oWHDhik/P19xcXFavXq1goKCzPpp06bJ29tbffr00YkTJ9ShQwfNnz9fXl5eZs3ixYs1cuRI82m0nj17asaMGVV7gQAA4KLg1kBkGMY5a2w2m5KTk5WcnHzGmlq1aunll1/Wyy+/fMaa4OBgLVq0qCJtAgCAGs4jFlUDAAC4E4EIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYHoEIAABYnre7GwDOR+s9cy7wCM9XSh8AgJqFGSIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5bg1En332mXr06KHw8HDZbDatWLHCab9hGEpOTlZ4eLj8/f3Vrl07bd++3ammsLBQI0aMUP369RUYGKiePXtq3759TjX5+flKTEyU3W6X3W5XYmKiDh8+XMVXBwAALhZuDUTHjh3TNddcoxkzZpS5f8qUKUpLS9OMGTO0efNmhYWFqVOnTjpy5IhZk5SUpOXLl2vZsmVav369jh49qu7du6ukpMSs6devn7Kzs5WRkaGMjAxlZ2crMTGxyq8PAABcHLzdefKuXbuqa9euZe4zDEPTp0/XhAkT1Lt3b0nSggULFBoaqiVLlmjo0KFyOByaN2+e3njjDXXs2FGStGjRIkVERGjNmjXq3LmzduzYoYyMDGVlZSkuLk6SNHfuXMXHx2vnzp1q3rx59VwsAADwWB67hmj37t3Kzc1VQkKCOebn56e2bdtqw4YNkqStW7equLjYqSY8PFwxMTFmzcaNG2W3280wJEmtW7eW3W43a8pSWFiogoICpw0AANRMHhuIcnNzJUmhoaFO46Ghoea+3Nxc+fr6qm7dumetCQkJcTl+SEiIWVOW1NRUc82R3W5XRETEBV0PAADwXB4biErZbDan14ZhuIyd7vSasurPdZzx48fL4XCY2969e8+zcwAAcLHw2EAUFhYmSS6zOHl5eeasUVhYmIqKipSfn3/WmgMHDrgc/+DBgy6zT3/l5+en2rVrO20AAKBm8thAFBkZqbCwMGVmZppjRUVFWrdundq0aSNJatWqlXx8fJxqcnJytG3bNrMmPj5eDodDmzZtMmu++OILORwOswYAAFibW58yO3r0qH744Qfz9e7du5Wdna3g4GA1atRISUlJSklJUVRUlKKiopSSkqKAgAD169dPkmS32zVo0CCNGTNG9erVU3BwsMaOHauWLVuaT51FR0erS5cuGjx4sGbPni1JGjJkiLp3784TZgAAQJKbA9GWLVvUvn178/Xo0aMlSQMGDND8+fM1btw4nThxQsOGDVN+fr7i4uK0evVqBQUFme+ZNm2avL291adPH504cUIdOnTQ/Pnz5eXlZdYsXrxYI0eONJ9G69mz5xm/+wgAAFiPWwNRu3btZBjGGffbbDYlJycrOTn5jDW1atXSyy+/rJdffvmMNcHBwVq0aNGFtAoAAGowj11DBAAAUF3cOkMEAJ6i9Z455y5aW6/s8fbjK7cZANWOGSIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB5BCIAAGB53u5uAAAATzYtc1elHOexTs0q5TioGswQAQAAyyMQAQAAyyMQAQAAy7NUIJo5c6YiIyNVq1YttWrVSv/973/d3RIAAPAAlllU/eabbyopKUkzZ87UjTfeqNmzZ6tr16763//+p0aNGrm7PQBwGxYNAxaaIUpLS9OgQYP00EMPKTo6WtOnT1dERIRmzZrl7tYAAICbWWKGqKioSFu3btUTTzzhNJ6QkKANGza4qSsAAC5+NWWG0RKB6NChQyopKVFoaKjTeGhoqHJzc8t8T2FhoQoLC83XDodDklRQUFDp/b3yyQ+VcpzhtzatlON4mj+OHTX/fOxE4Vkqz60q/vl5gr/eo7863/tVcOyPv7yoOffqTPfnr8pzr5zuj9OOi/telef+/NXf96WXOV5QGHzuN98y5rzO5QnO9/781V/vVbnuz19dJPfqQu7PX1XV/z+XHtcwjLPWWSIQlbLZbE6vDcNwGSuVmpqqp556ymU8IiKiSnqrDP90dwMXgxEz3N3BReRpdzdwEeFelR/3qvysda+q+u+wI0eOyG63n3G/JQJR/fr15eXl5TIblJeX5zJrVGr8+PEaPXq0+frUqVP6/fffVa9evTOGqIooKChQRESE9u7dq9q1a1facWsi7tX54X6VH/eq/LhX5ce9Kr+qvFeGYejIkSMKDw8/a50lApGvr69atWqlzMxM3XHHHeZ4ZmamevXqVeZ7/Pz85Ofn5zRWp06dKuuxdu3a/A+mnLhX54f7VX7cq/LjXpUf96r8qupenW1mqJQlApEkjR49WomJiYqNjVV8fLzmzJmjPXv26OGHH3Z3awAAwM0sE4j69u2r3377TU8//bRycnIUExOj//znP2rcuLG7WwMAAG5mmUAkScOGDdOwYcPc3YYTPz8/TZw40eXjObjiXp0f7lf5ca/Kj3tVftyr8vOEe2UzzvUcGgAAQA1nmW+qBgAAOBMCEQAAsDwCEQAAsDwCEQAAsDwCkZvNnDlTkZGRqlWrllq1aqX//ve/7m7JI3322Wfq0aOHwsPDZbPZtGLFCne35JFSU1P197//XUFBQQoJCdHtt9+unTt3urstjzRr1ixdffXV5hfBxcfH66OPPnJ3WxeF1NRU2Ww2JSUlubsVj5ScnCybzea0hYWFubstj/Xrr7+qf//+qlevngICAnTttddq69at1d4HgciN3nzzTSUlJWnChAn66quvdPPNN6tr167as2ePu1vzOMeOHdM111yjGTP4LbKzWbdunYYPH66srCxlZmbq5MmTSkhI0LFjx9zdmsdp2LChnnvuOW3ZskVbtmzRrbfeql69emn79u3ubs2jbd68WXPmzNHVV1/t7lY8WosWLZSTk2Nu3377rbtb8kj5+fm68cYb5ePjo48++kj/+9//9MILL1TpL0OcCY/du1FcXJyuv/56zZo1yxyLjo7W7bffrtTUVDd25tlsNpuWL1+u22+/3d2teLyDBw8qJCRE69at0y233OLudjxecHCwpk6dqkGDBrm7FY909OhRXX/99Zo5c6YmTZqka6+9VtOnT3d3Wx4nOTlZK1asUHZ2trtb8XhPPPGEPv/8c4/4dIQZIjcpKirS1q1blZCQ4DSekJCgDRs2uKkr1DQOh0PSn3/R48xKSkq0bNkyHTt2TPHx8e5ux2MNHz5ct912mzp27OjuVjze999/r/DwcEVGRuqee+7RTz/95O6WPNLKlSsVGxuru+++WyEhIbruuus0d+5ct/RCIHKTQ4cOqaSkRKGhoU7joaGhys3NdVNXqEkMw9Do0aN10003KSYmxt3teKRvv/1Wl156qfz8/PTwww9r+fLluuqqq9zdlkdatmyZvvzyS2avyyEuLk4LFy7UqlWrNHfuXOXm5qpNmzb67bff3N2ax/npp580a9YsRUVFadWqVXr44Yc1cuRILVy4sNp7sdRPd3gim83m9NowDJcxoCIeffRRffPNN1q/fr27W/FYzZs3V3Z2tg4fPqx3331XAwYM0Lp16whFp9m7d69GjRql1atXq1atWu5ux+N17drV/HPLli0VHx+vK664QgsWLNDo0aPd2JnnOXXqlGJjY5WSkiJJuu6667R9+3bNmjVL999/f7X2wgyRm9SvX19eXl4us0F5eXkus0bA+RoxYoRWrlyptWvXqmHDhu5ux2P5+vqqadOmio2NVWpqqq655hq9+OKL7m7L42zdulV5eXlq1aqVvL295e3trXXr1umll16St7e3SkpK3N2iRwsMDFTLli31/fffu7sVj9OgQQOXfwGJjo52y8NFBCI38fX1VatWrZSZmek0npmZqTZt2ripK1zsDMPQo48+qvfee0+ffPKJIiMj3d3SRcUwDBUWFrq7DY/ToUMHffvtt8rOzja32NhY3XfffcrOzpaXl5e7W/RohYWF2rFjhxo0aODuVjzOjTfe6PLVILt27VLjxo2rvRc+MnOj0aNHKzExUbGxsYqPj9ecOXO0Z88ePfzww+5uzeMcPXpUP/zwg/l69+7dys7OVnBwsBo1auTGzjzL8OHDtWTJEr3//vsKCgoyZyDtdrv8/f3d3J1n+ec//6muXbsqIiJCR44c0bJly/Tpp58qIyPD3a15nKCgIJd1aIGBgapXrx7r08owduxY9ejRQ40aNVJeXp4mTZqkgoICDRgwwN2teZzHHntMbdq0UUpKivr06aNNmzZpzpw5mjNnTvU3Y8CtXnnlFaNx48aGr6+vcf311xvr1q1zd0seae3atYYkl23AgAHubs2jlHWPJBnp6enubs3jDBw40Pzf3mWXXWZ06NDBWL16tbvbumi0bdvWGDVqlLvb8Eh9+/Y1GjRoYPj4+Bjh4eFG7969je3bt7u7LY/1wQcfGDExMYafn59x5ZVXGnPmzHFLH3wPEQAAsDzWEAEAAMsjEAEAAMsjEAEAAMsjEAEAAMsjEAEAAMsjEAEAAMsjEAEAAMsjEAEAAMsjEAGoFg888IBsNpvL1qVLF0lSkyZNzDF/f381adJEffr00SeffOJ0nE8//VQ2m02HDx92Oce1116r5ORkp7GvvvpKd999t0JDQ1WrVi01a9ZMgwcP1q5du1zen5CQIC8vL2VlZUmSfv755zJ7/uuWnJxs1mVnZzsdb8GCBbrhhhsUGBiooKAg3XLLLfrwww/LvJ6YmBiXH0mtU6eO5s+fX467C+BCEYgAVJsuXbooJyfHaVu6dKm5/+mnn1ZOTo527typhQsXqk6dOurYsaOeffbZCp3vww8/VOvWrVVYWKjFixdrx44deuONN2S32/Xkk0861e7Zs0cbN27Uo48+qnnz5kmSIiIinHodM2aMWrRo4TQ2duzYMs89duxYDR06VH369NHXX3+tTZs26eabb1avXr00Y8YMl/off/xRCxcurNB1Arhw/LgrgGrj5+ensLCwM+4PCgoy9zdq1Ei33HKLGjRooH/961+666671Lx583Kf6/jx43rwwQfVrVs3LV++3ByPjIxUXFycywxTenq6unfvrkceeUQ33HCDpk+frsDAQKd+L730Unl7e7tcw6FDh5xeZ2Vl6YUXXtBLL72kESNGmOPPPvus/vjjD40ePVq9evVSRESEuW/EiBGaOHGi7r33XtWqVavc1wmgcjBDBMCjjRo1SoZh6P333z+v961atUqHDh3SuHHjytxfp04d88+GYSg9PV39+/fXlVdeqWbNmumtt96qcM9Lly7VpZdeqqFDh7rsGzNmjIqLi/Xuu+86jSclJenkyZNlzh4BqHoEIgDV5sMPP9Sll17qtD3zzDNnfU9wcLBCQkL0888/n9e5vv/+e0nSlVdeec7aNWvW6Pjx4+rcubMkqX///ubHZhWxa9cuXXHFFfL19XXZFx4eLrvd7rKGKSAgQBMnTlRqaqocDkeFzw2gYghEAKpN+/btlZ2d7bQNHz78nO8zDEM2m+28zmUYRrlr582bp759+8rb+89VBPfee6+++OIL7dy587zOeT69lXU9gwYNUv369TV58uQqOS+AMyMQAag2gYGBatq0qdMWHBx81vf89ttvOnjwoCIjIyVJtWvXlqQyZ1EOHz4su90uSWrWrJkk6bvvvjvr8X///XetWLFCM2fOlLe3t7y9vfW3v/1NJ0+e1Ouvv37e11h67h9//FFFRUUu+/bv36+CggJFRUW57PP29takSZP04osvav/+/RU6N4CKIRAB8GgvvviiLrnkEt1+++2SpKioKF1yySXavHmzU11OTo5+/fVXc+F1QkKC6tevrylTppR53NJF1YsXL1bDhg319ddfO81cTZ8+XQsWLNDJkyfPu+d77rlHR48e1ezZs132Pf/88/Lx8dGdd95Z5nvvvvtutWjRQk899dR5nxdAxfGUGYBqU1hYqNzcXKcxb29v1a9fX5J05MgR5ebmqri4WLt379aiRYv02muvKTU1VU2bNpX055NoQ4cO1ZgxY+Tt7a1rrrlG+/fv14QJExQdHa2EhARJf85Gvfbaa7r77rvVs2dPjRw5Uk2bNtWhQ4f01ltvac+ePVq2bJnmzZunu+66SzExMU59NW7cWI8//rj+/e9/q1evXud1nfHx8Ro1apT+8Y9/qKioSLfffruKi4u1aNEivfjii5o+fbrTE2ane+6558z1TACqiQEA1WDAgAGGJJetefPmhmEYRuPGjc0xX19fo1GjRkafPn2MTz75xOVYf/zxh/H0008b0dHRhr+/v9G4cWPjgQceMHJyclxqN2/ebPTu3du47LLLDD8/P6Np06bGkCFDjO+//97YsmWLIcnYtGlTmT336NHD6NGjh/l64sSJxjXXXONSt3v3bkOS8dVXXzmNz5s3z4iNjTX8/f2NgIAA46abbjJWrlzpVLN27VpDkpGfn+80npCQYEgy0tPTy+wNQOWyGcZ5rDwEAACogVhDBAAALI9ABAAALI9ABAAALI9ABAAALI9ABAAALI9ABAAALI9ABAAALI9ABAAALI9ABAAALI9ABAAALI9ABAAALI9ABAAALO//Az+Vja842bFuAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlsAAAHFCAYAAADFQTzfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABJKElEQVR4nO3deViVdf7/8deRTUA4KgSIklrhFtoik2KLmHuSLfMdNZU0rXQsi9SpMa/5acuAyze1GSczI8wybcp0bKZILJcpl0wjl0wrzRVEC8EtUPj8/ujH/fPIoh65PXh8Pq7rXFfnc7/PfX/egPDqc+77Pg5jjBEAAABsUcvTEwAAAPBmhC0AAAAbEbYAAABsRNgCAACwEWELAADARoQtAAAAGxG2AAAAbETYAgAAsBFhCwAAwEaELcAD5syZI4fDoa+++qrC7UlJSWrSpInLWJMmTTR48OALOs7q1as1YcIEHTlyxL2JXoHeffddXX/99QoMDJTD4VB2dnaFdStWrJDD4XB51KtXT+3atdObb75Zrr5JkyZKSkpyGXM4HHr88cernE9iYqLi4uLc7udsmzdvlsPhkJ+fn3Jycio9psPh0DXXXKOKPmRk1apVVs9z5syRpHJfi8oeK1assPaze/duDRkyRNHR0QoICFDDhg113333VVuvQE3h6+kJADg/ixYtUmho6AW9ZvXq1Xruuec0ePBg1a1b156JeZFDhw4pOTlZPXr00CuvvKKAgAA1a9asytekpqaqU6dOkqTDhw9r7ty5Gjx4sAoLCzVy5MhLMe0L8vrrr0uSTp8+rblz5+qZZ56psC4kJES7du3SZ599ps6dO7tse+ONNxQaGqrCwkJrbM2aNS41L7zwgpYvX67PPvvMZbxVq1aSpC1btigxMVHXXHON/vd//1eNGjVSTk6OPvnkk4vuEahpCFvAZeKmm27y9BQu2KlTp+RwOOTre3n8qtmxY4dOnTqlgQMHqmPHjuf1mtjYWLVv3956ftddd2n9+vWaP39+jQtbRUVFmjdvnm644QYdPnxYb7zxRqVh6+qrr1ZISIjeeOMNl7B19OhRvffeexowYIBmz55tjZ/5NZCkq666SrVq1So3LknGGCUnJysmJkb//e9/FRAQYG3r27fvxbYJ1Di8jQhcJs5+G7G0tFQvvviimjdvrsDAQNWtW1dt2rTRyy+/LEmaMGGC/vSnP0mSmjZtWu5tnNLSUk2ePFktWrRQQECAIiIi9OCDD2rfvn0uxzXGKDU1VY0bN1bt2rUVHx+vrKwsJSYmKjEx0aore1vtrbfe0ujRo9WwYUMFBATohx9+0KFDhzRixAi1atVKderUUUREhO68807997//dTnWTz/9JIfDoSlTpmjSpElq0qSJAgMDlZiYaAWhP//5z4qOjpbT6dR9992nvLy88/r6LVmyRAkJCQoKClJISIi6du3qshozePBg3XbbbZJ++4PvcDhc+jtftWrVUp06deTn53fBr7Xb4sWL9fPPP+vhhx/WoEGDtGPHDn3++eeV1g8ZMkQffPCBy9vQCxYskCT169fP7XmsWrVK2dnZSklJcQlagLcibAEeVFJSotOnT5d7VHSezNkmT56sCRMm6IEHHtB//vMfvfvuuxo6dKj1h/Hhhx+2VlY++OADrVmzRmvWrNHNN98sSfrjH/+oZ555Rl27dtWSJUv0wgsvKDMzUx06dNDhw4et44wbN07jxo1Tjx499K9//UvDhw/Xww8/rB07dlQ4r7Fjx2rPnj169dVX9eGHHyoiIkK//PKLJGn8+PH6z3/+o4yMDF1zzTVKTEx0OYenzD/+8Q998cUX+sc//qHXX39d3333ne6++24NHTpUhw4d0htvvKHJkydr2bJlevjhh8/5tXrnnXd0zz33KDQ0VPPnz1d6erry8/OVmJhohY2//OUv+sc//iHpt7cG16xZo1deeeWc+y4tLbW+bwcPHtTEiRO1ZcsWDRw48JyvvdTS09MVEBCgAQMGaMiQIXI4HEpPT6+0vl+/fvLx8dH8+fNd9vE///M/F/yW9plWrVol6be3Ku+66y7Vrl1bderUUVJSkr777ju39wvUWAbAJZeRkWEkVflo3Lixy2saN25sBg0aZD1PSkoyN954Y5XHmTJlipFkdu3a5TK+bds2I8mMGDHCZXzdunVGknn22WeNMcb88ssvJiAgwPTt29elbs2aNUaS6dixozW2fPlyI8nccccd5+z/9OnT5tSpU6Zz587mvvvus8Z37dplJJkbbrjBlJSUWOPTp083kkzv3r1d9pOSkmIkmYKCgkqPVVJSYqKjo03r1q1d9nn06FETERFhOnToUK6H995775w9lNWe/ahVq5YZN25cufrGjRubXr16uYxJMo899liVx+nYsaO5/vrrzzmfc/npp59MrVq1TL9+/Vz2HRwcbAoLCys95qBBg0x8fLwxxpitW7caSWbFihVm/fr1RpLJyMio8HiDBg0ywcHBFW4bNmyYkWRCQ0PN0KFDzbJly8xbb71lGjdubMLDw82BAwcuul+gJmFlC/CguXPnav369eUeZW9nVeWWW27RN998oxEjRuiTTz5xOVn5XJYvXy5J5a5uvOWWW9SyZUt9+umnkqS1a9eqqKhIffr0calr3759uasly/z+97+vcPzVV1/VzTffrNq1a8vX11d+fn769NNPtW3btnK1d911l2rV+v+/nlq2bClJ6tWrl0td2fiePXsq6VTavn27Dhw4oOTkZJd91qlTR7///e+1du1anThxotLXn8ukSZOs71tWVpaefvppTZw40XoLt6bIyMhQaWmphgwZYo0NGTJEx48f17vvvlvp64YMGaKvvvpKmzdvVnp6uq699lrdcccdFzWX0tJSSVJCQoJef/11de7cWQMHDtTixYt1+PBha4UR8BaXx1mrgJdq2bKl4uPjy407nU7t3bu3yteOHTtWwcHBevvtt/Xqq6/Kx8dHd9xxhyZNmlThPs/0888/S5IaNGhQblt0dLR2797tUhcZGVmurqKxyvY5depUjR49WsOHD9cLL7yg8PBw+fj46C9/+UuFYat+/fouz/39/asc//XXXyucy5k9VNZraWmp8vPzFRQUVOk+qnLNNde4fL27dOmi/Px8vfTSSxo6dKhatGjh1n6rU2lpqebMmaPo6Gi1bdvWequ5S5cuCg4OVnp6eqVvx95xxx2KjY3VrFmz9M9//lMpKSlyOBwXNZ+wsDBJUvfu3V3Gb7zxRjVo0EAbN268qP0DNQ0rW8BlytfXV6NGjdLGjRv1yy+/aP78+dq7d6+6d+9+zpWasj92Fd1n6cCBAwoPD3epO3jwYLm63NzcCvdd0R/it99+W4mJiZo5c6Z69eqldu3aKT4+XkePHq26yWpwrl5r1aqlevXqVesx27RpI2OMNm3aVK37ddeyZcu0e/duHThwQGFhYapXr57q1aunhg0b6vjx41q7dq2+/fbbSl//0EMPaebMmfrll180aNCgi55PmzZtKt1mjHFZgQS8AT/RgBeoW7eu/ud//kePPfaYfvnlF/3000+SZF3pdfLkSZf6O++8U9JvIehM69ev17Zt26xL/du1a6eAgIBybzOtXbvWWv06Hw6Ho9xVZ5s2bSp3byY7NG/eXA0bNtQ777zjcuHB8ePHtXDhQusKxepUdiPUiIiIat2vu9LT01WrVi0tXrxYy5cvd3m89dZbkn67d1ZlBg0apLvvvlt/+tOf1LBhw4ueT8+ePRUUFKSPP/7YZXzjxo3Kzc2t8HYRwOWMtxGBy9Tdd9+tuLg4xcfH66qrrtLu3bs1ffp0NW7cWLGxsZKk1q1bS5JefvllDRo0SH5+fmrevLmaN2+uRx99VH//+99Vq1Yt9ezZUz/99JP+8pe/KCYmRk899ZSk3962GzVqlNLS0lSvXj3dd9992rdvn5577jk1aNDgvFcgkpKS9MILL2j8+PHq2LGjtm/frueff15NmzbV6dOn7fkC/T+1atXS5MmTNWDAACUlJWnYsGEqKirSlClTdOTIEU2cOPGi9v/9999r7dq1kqSCggItW7ZM6enpio+P1+23337O1//44496//33y423atXKugFoYWFhhTVXXXXVOe8H9vPPP+tf//qXunfvrnvuuafCmmnTpmnu3LlKS0ur8JYV0dHRWrx48Tl7OV9169bV888/rzFjxmjw4MF64IEHlJubq7/85S+6+uqrNWLEiGo7FlAjePgEfeCKVHY14vr16yvc3qtXr3NejfjSSy+ZDh06mPDwcOPv72+uvvpqM3ToUPPTTz+5vG7s2LEmOjra1KpVy0gyy5cvN8b8dpXepEmTTLNmzYyfn58JDw83AwcONHv37nV5fWlpqXnxxRdNo0aNjL+/v2nTpo3597//bW644QaXKwmrupKvqKjIjBkzxjRs2NDUrl3b3HzzzWbx4sVm0KBBLn2WXY04ZcoUl9dXtu9zfR3PtHjxYtOuXTtTu3ZtExwcbDp37my++OKL8zpORSq6GjE4ONi0atXKjB8/vtwVkpVdjVjZY/z48caY364MrKzmzKtBK1N2JefixYsrrXn11VeNJLNw4ULrmOe6AvJirkYsM3v2bBMXF2f8/f1NWFiYGTBgQLmfP8AbOIw5jxv6AMAZdu3apRYtWmj8+PF69tlnPT0dAKjRCFsAqvTNN99o/vz56tChg0JDQ7V9+3ZNnjxZhYWF2rJlS6VXJQIAfsM5WwCqFBwcrK+++krp6ek6cuSInE6nEhMT9de//pWg5WHGGJWUlFRZ4+Pjc9G3agBwcVjZAoDL1IoVK9SpU6cqazIyMsrdvBbApUXYAoDL1NGjR7V9+/Yqa5o2bWrdawyAZxC2AAAAbMRNTQEAAGzECfLnqbS0VAcOHFBISAgnmwIAcJkwxujo0aOKjo722EdBEbbO04EDBxQTE+PpaQAAADfs3btXjRo18sixCVvnKSQkRNJv36zQ0FAPzwYAAJyPwsJCxcTEWH/HPYGwdZ7K3joMDQ0lbAEAcJnx5ClAnCAPAABgI8IWAACAjQhbAAAANuKcLQAAvFxJSYlOnTrl6WnYws/PTz4+Pp6eRpUIWwAAeCljjHJzc3XkyBFPT8VWdevWVVRUVI29DyZhCwAAL1UWtCIiIhQUFFRjw4i7jDE6ceKE8vLyJEkNGjTw8IwqRtgCAMALlZSUWEHLmz+MPDAwUJKUl5eniIiIGvmWIifIAwDghcrO0QoKCvLwTOxX1mNNPS+NsAUAgBfztrcOK1LTeyRsAQAA2IiwBQAAYCNOkAcA4AozLWvHJTvWU12bufW6V155RVOmTFFOTo6uv/56TZ8+Xbfffns1z+7SYGULAADUKO+++65SUlI0btw4ff3117r99tvVs2dP7dmzx9NTcwthCwAA1ChTp07V0KFD9fDDD6tly5aaPn26YmJiNHPmTE9PzS2ELQAAUGMUFxdrw4YN6tatm8t4t27dtHr1ag/N6uJwzhbghuo638HdcxkAwFsdPnxYJSUlioyMdBmPjIxUbm6uh2Z1cVjZAgAANc7Z984yxtT4+2lVhrAFAABqjPDwcPn4+JRbxcrLyyu32nW5IGwBAIAaw9/fX23btlVWVpbLeFZWljp06OChWV0cztkCAAA1yqhRo5ScnKz4+HglJCTotdde0549ezR8+HBPT80thC0AAFCj9O3bVz///LOef/555eTkKC4uTh999JEaN27s6am5hbAFAMAV5nK4EnrEiBEaMWKEp6dRLThnCwAAwEaELQAAABsRtgAAAGxE2AIAALARYQsAAMBGhC0AAAAbEbYAAABsRNgCAACwEWELAADARoQtAAAAG/FxPQAAXGmWp126Y3Uae8EvWbVqlaZMmaINGzYoJydHixYt0r333lv9c7tEWNkCAAA1yvHjx3XDDTdoxowZnp5KtWBlCwAA1Cg9e/ZUz549PT2NasPKFgAAgI0IWwAAADYibAEAANiIsAUAAGAjwhYAAICNuBoRAADUKMeOHdMPP/xgPd+1a5eys7NVv359XX311R6cmXsIWwAAoEb56quv1KlTJ+v5qFGjJEmDBg3SnDlzPDQr9xG2AAC40rhxV/dLKTExUcYYT0+j2nj8nK39+/dr4MCBCgsLU1BQkG688UZt2LDB2m6M0YQJExQdHa3AwEAlJiZq69atLvsoKirSyJEjFR4eruDgYPXu3Vv79u1zqcnPz1dycrKcTqecTqeSk5N15MiRS9EiAAC4gnk0bOXn5+vWW2+Vn5+fPv74Y3377bd66aWXVLduXatm8uTJmjp1qmbMmKH169crKipKXbt21dGjR62alJQULVq0SAsWLNDnn3+uY8eOKSkpSSUlJVZN//79lZ2drczMTGVmZio7O1vJycmXsl0AAHAF8ujbiJMmTVJMTIwyMjKssSZNmlj/bYzR9OnTNW7cON1///2SpDfffFORkZF65513NGzYMBUUFCg9PV1vvfWWunTpIkl6++23FRMTo2XLlql79+7atm2bMjMztXbtWrVr106SNHv2bCUkJGj79u1q3rz5pWsaAABcUTy6srVkyRLFx8frD3/4gyIiInTTTTdp9uzZ1vZdu3YpNzdX3bp1s8YCAgLUsWNHrV69WpK0YcMGnTp1yqUmOjpacXFxVs2aNWvkdDqtoCVJ7du3l9PptGrOVlRUpMLCQpcHAADAhfJo2Nq5c6dmzpyp2NhYffLJJxo+fLieeOIJzZ07V5KUm5srSYqMjHR5XWRkpLUtNzdX/v7+qlevXpU1ERER5Y4fERFh1ZwtLS3NOr/L6XQqJibm4poFAMADvOlE88rU9B49GrZKS0t18803KzU1VTfddJOGDRumRx55RDNnznSpczgcLs+NMeXGznZ2TUX1Ve1n7NixKigosB579+4937YAAPA4Pz8/SdKJEyc8PBP7lfVY1nNN49Fztho0aKBWrVq5jLVs2VILFy6UJEVFRUn6bWWqQYMGVk1eXp612hUVFaXi4mLl5+e7rG7l5eWpQ4cOVs3BgwfLHf/QoUPlVs3KBAQEKCAg4CK6AwDAc3x8fFS3bl3l5eVJkoKCgs65UHG5McboxIkTysvLU926deXj4+PpKVXIo2Hr1ltv1fbt213GduzYocaNG0uSmjZtqqioKGVlZemmm26SJBUXF2vlypWaNGmSJKlt27by8/NTVlaW+vTpI0nKycnRli1bNHnyZElSQkKCCgoK9OWXX+qWW26RJK1bt04FBQVWIAMAwNuULVqUBS5vVbduXavXmsijYeupp55Shw4dlJqaqj59+ujLL7/Ua6+9ptdee03Sb2/9paSkKDU1VbGxsYqNjVVqaqqCgoLUv39/SZLT6dTQoUM1evRohYWFqX79+hozZoxat25tXZ3YsmVL9ejRQ4888ohmzZolSXr00UeVlJTElYgAAK/lcDjUoEEDRURE6NSpU56eji38/Pxq7IpWGY+Grd/97ndatGiRxo4dq+eff15NmzbV9OnTNWDAAKvm6aef1smTJzVixAjl5+erXbt2Wrp0qUJCQqyaadOmydfXV3369NHJkyfVuXNnzZkzx+WLP2/ePD3xxBPWVYu9e/fWjBkzLl2zAAB4iI+PT40PJN7MYWr6Kfw1RGFhoZxOpwoKChQaGurp6cDDpmXtqJb9PNW1WbXsBwBQsZrw99vjH9cDAADgzQhbAAAANiJsAQAA2IiwBQAAYCPCFgAAgI0IWwAAADYibAEAANiIsAUAAGAjwhYAAICNCFsAAAA2ImwBAADYiLAFAABgI8IWAACAjQhbAAAANiJsAQAA2IiwBQAAYCPCFgAAgI0IWwAAADYibAEAANiIsAUAAGAjwhYAAICNCFsAAAA2ImwBAADYiLAFAABgI8IWAACAjQhbAAAANiJsAQAA2IiwBQAAYCPCFgAAgI0IWwAAADYibAEAANiIsAUAAGAjwhYAAICNCFsAAAA2ImwBAADYiLAFAABgI8IWAACAjQhbAAAANiJsAQAA2IiwBQAAYCPCFgAAgI0IWwAAADbyaNiaMGGCHA6HyyMqKsrabozRhAkTFB0drcDAQCUmJmrr1q0u+ygqKtLIkSMVHh6u4OBg9e7dW/v27XOpyc/PV3JyspxOp5xOp5KTk3XkyJFL0SIAALjCeXxl6/rrr1dOTo712Lx5s7Vt8uTJmjp1qmbMmKH169crKipKXbt21dGjR62alJQULVq0SAsWLNDnn3+uY8eOKSkpSSUlJVZN//79lZ2drczMTGVmZio7O1vJycmXtE8AAHBl8vX4BHx9XVazyhhjNH36dI0bN07333+/JOnNN99UZGSk3nnnHQ0bNkwFBQVKT0/XW2+9pS5dukiS3n77bcXExGjZsmXq3r27tm3bpszMTK1du1bt2rWTJM2ePVsJCQnavn27mjdvfumaBQAAVxyPr2x9//33io6OVtOmTdWvXz/t3LlTkrRr1y7l5uaqW7duVm1AQIA6duyo1atXS5I2bNigU6dOudRER0crLi7OqlmzZo2cTqcVtCSpffv2cjqdVg0AAIBdPLqy1a5dO82dO1fNmjXTwYMH9eKLL6pDhw7aunWrcnNzJUmRkZEur4mMjNTu3bslSbm5ufL391e9evXK1ZS9Pjc3VxEREeWOHRERYdVUpKioSEVFRdbzwsJC95oEAABXNI+GrZ49e1r/3bp1ayUkJOjaa6/Vm2++qfbt20uSHA6Hy2uMMeXGznZ2TUX159pPWlqannvuufPqAwAAoDIefxvxTMHBwWrdurW+//576zyus1ef8vLyrNWuqKgoFRcXKz8/v8qagwcPljvWoUOHyq2anWns2LEqKCiwHnv37r2o3gAAwJWpRoWtoqIibdu2TQ0aNFDTpk0VFRWlrKwsa3txcbFWrlypDh06SJLatm0rPz8/l5qcnBxt2bLFqklISFBBQYG+/PJLq2bdunUqKCiwaioSEBCg0NBQlwcAAMCF8ujbiGPGjNHdd9+tq6++Wnl5eXrxxRdVWFioQYMGyeFwKCUlRampqYqNjVVsbKxSU1MVFBSk/v37S5KcTqeGDh2q0aNHKywsTPXr19eYMWPUunVr6+rEli1bqkePHnrkkUc0a9YsSdKjjz6qpKQkrkQEAAC282jY2rdvnx544AEdPnxYV111ldq3b6+1a9eqcePGkqSnn35aJ0+e1IgRI5Sfn6927dpp6dKlCgkJsfYxbdo0+fr6qk+fPjp58qQ6d+6sOXPmyMfHx6qZN2+ennjiCeuqxd69e2vGjBmXtlkAAHBFchhjjKcncTkoLCyU0+lUQUEBbylC07J2VMt+nurarFr2AwCoWE34+12jztkCAADwNoQtAAAAGxG2AAAAbOTxz0YErmSc+wUA3o+VLQAAABsRtgAAAGxE2AIAALARYQsAAMBGhC0AAAAbEbYAAABsRNgCAACwEWELAADARoQtAAAAGxG2AAAAbETYAgAAsBFhCwAAwEaELQAAABsRtgAAAGxE2AIAALARYQsAAMBGhC0AAAAbEbYAAABsRNgCAACwEWELAADARoQtAAAAGxG2AAAAbETYAgAAsBFhCwAAwEaELQAAABsRtgAAAGxE2AIAALARYQsAAMBGhC0AAAAbEbYAAABsRNgCAACwEWELAADARoQtAAAAGxG2AAAAbETYAgAAsBFhCwAAwEaELQAAABsRtgAAAGzkVtjatWtXdc8DAADAK7kVtq677jp16tRJb7/9tn799ddqmUhaWpocDodSUlKsMWOMJkyYoOjoaAUGBioxMVFbt251eV1RUZFGjhyp8PBwBQcHq3fv3tq3b59LTX5+vpKTk+V0OuV0OpWcnKwjR45Uy7wBAACq4lbY+uabb3TTTTdp9OjRioqK0rBhw/Tll1+6PYn169frtddeU5s2bVzGJ0+erKlTp2rGjBlav369oqKi1LVrVx09etSqSUlJ0aJFi7RgwQJ9/vnnOnbsmJKSklRSUmLV9O/fX9nZ2crMzFRmZqays7OVnJzs9nwBAADOl1thKy4uTlOnTtX+/fuVkZGh3Nxc3Xbbbbr++us1depUHTp06Lz3dezYMQ0YMECzZ89WvXr1rHFjjKZPn65x48bp/vvvV1xcnN58802dOHFC77zzjiSpoKBA6enpeumll9SlSxfddNNNevvtt7V582YtW7ZMkrRt2zZlZmbq9ddfV0JCghISEjR79mz9+9//1vbt291pHwAA4Lxd1Anyvr6+uu+++/TPf/5TkyZN0o8//qgxY8aoUaNGevDBB5WTk3POfTz22GPq1auXunTp4jK+a9cu5ebmqlu3btZYQECAOnbsqNWrV0uSNmzYoFOnTrnUREdHKy4uzqpZs2aNnE6n2rVrZ9W0b99eTqfTqqlIUVGRCgsLXR4AAAAX6qLC1ldffaURI0aoQYMGmjp1qsaMGaMff/xRn332mfbv36977rmnytcvWLBAGzduVFpaWrltubm5kqTIyEiX8cjISGtbbm6u/P39XVbEKqqJiIgot/+IiAirpiJpaWnWOV5Op1MxMTFV9gIAAFARX3deNHXqVGVkZGj79u266667NHfuXN11112qVeu37Na0aVPNmjVLLVq0qHQfe/fu1ZNPPqmlS5eqdu3aldY5HA6X58aYcmNnO7umovpz7Wfs2LEaNWqU9bywsJDABQAALphbYWvmzJkaMmSIHnroIUVFRVVYc/XVVys9Pb3SfWzYsEF5eXlq27atNVZSUqJVq1ZpxowZ1vlUubm5atCggVWTl5dnrXZFRUWpuLhY+fn5LqtbeXl56tChg1Vz8ODBcsc/dOhQuVWzMwUEBCggIKDS7QAAAOfDrbcRv//+e40dO7bSoCVJ/v7+GjRoUKXbO3furM2bNys7O9t6xMfHa8CAAcrOztY111yjqKgoZWVlWa8pLi7WypUrrSDVtm1b+fn5udTk5ORoy5YtVk1CQoIKCgpcrpZct26dCgoKrBoAAAC7uLWylZGRoTp16ugPf/iDy/h7772nEydOVBmyyoSEhCguLs5lLDg4WGFhYdZ4SkqKUlNTFRsbq9jYWKWmpiooKEj9+/eXJDmdTg0dOlSjR49WWFiY6tevrzFjxqh169bWCfctW7ZUjx499Mgjj2jWrFmSpEcffVRJSUlq3ry5O+0DAACcN7dWtiZOnKjw8PBy4xEREUpNTb3oSZV5+umnlZKSohEjRig+Pl779+/X0qVLFRISYtVMmzZN9957r/r06aNbb71VQUFB+vDDD+Xj42PVzJs3T61bt1a3bt3UrVs3tWnTRm+99Va1zRMAAKAyDmOMudAX1a5dW999952aNGniMv7TTz+pZcuWOnnyZHXNr8YoLCyU0+lUQUGBQkNDPT0deNi0rB2enoKLp7o28/QUAKBGqgl/v91a2YqIiNCmTZvKjX/zzTcKCwu76EkBAAB4C7fCVr9+/fTEE09o+fLlKikpUUlJiT777DM9+eST6tevX3XPEQAA4LLl1gnyL774onbv3q3OnTvL1/e3XZSWlurBBx+s1nO2AAAALnduhS1/f3+9++67euGFF/TNN98oMDBQrVu3VuPGjat7fgAAAJc1t8JWmWbNmqlZM07MBQAAqIxbYaukpERz5szRp59+qry8PJWWlrps/+yzz6plcgAAAJc7t8LWk08+qTlz5qhXr16Ki4s752cVAgAAXKncClsLFizQP//5T911113VPR8AAACv4tatH/z9/XXddddV91wAAAC8jltha/To0Xr55Zflxs3nAQAArihuvY34+eefa/ny5fr44491/fXXy8/Pz2X7Bx98UC2TAwAAuNy5Fbbq1q2r++67r7rnAgAA4HXcClsZGRnVPQ8AAACv5NY5W5J0+vRpLVu2TLNmzdLRo0clSQcOHNCxY8eqbXIAAACXO7dWtnbv3q0ePXpoz549KioqUteuXRUSEqLJkyfr119/1auvvlrd8wQAALgsubWy9eSTTyo+Pl75+fkKDAy0xu+77z59+umn1TY5AACAy53bVyN+8cUX8vf3dxlv3Lix9u/fXy0TAwAA8AZurWyVlpaqpKSk3Pi+ffsUEhJy0ZMCAADwFm6Fra5du2r69OnWc4fDoWPHjmn8+PF8hA8AAMAZ3Hobcdq0aerUqZNatWqlX3/9Vf3799f333+v8PBwzZ8/v7rnCAAAcNlyK2xFR0crOztb8+fP18aNG1VaWqqhQ4dqwIABLifMAwAAXOncCluSFBgYqCFDhmjIkCHVOR8AAACv4lbYmjt3bpXbH3zwQbcmAwAA4G3cCltPPvmky/NTp07pxIkT8vf3V1BQEGELAADg/3HrasT8/HyXx7Fjx7R9+3bddtttnCAPAABwBrc/G/FssbGxmjhxYrlVLwAAgCtZtYUtSfLx8dGBAweqc5cAAACXNbfO2VqyZInLc2OMcnJyNGPGDN16663VMjEAAABv4FbYuvfee12eOxwOXXXVVbrzzjv10ksvVce8AAAAvIJbYau0tLS65wEAAOCVqvWcLQAAALhya2Vr1KhR5107depUdw4BAADgFdwKW19//bU2btyo06dPq3nz5pKkHTt2yMfHRzfffLNV53A4qmeWAAAAlym3wtbdd9+tkJAQvfnmm6pXr56k3250+tBDD+n222/X6NGjq3WSAAAAlyu3ztl66aWXlJaWZgUtSapXr55efPFFrkYEAAA4g1thq7CwUAcPHiw3npeXp6NHj170pAAAALyFW2Hrvvvu00MPPaT3339f+/bt0759+/T+++9r6NChuv/++6t7jgAAAJctt87ZevXVVzVmzBgNHDhQp06d+m1Hvr4aOnSopkyZUq0TBAAAuJy5FbaCgoL0yiuvaMqUKfrxxx9ljNF1112n4ODg6p4fAADAZe2ibmqak5OjnJwcNWvWTMHBwTLGVNe8AAAAvIJbYevnn39W586d1axZM911113KycmRJD388MPc9gEAAOAMboWtp556Sn5+ftqzZ4+CgoKs8b59+yozM7PaJgcAAHC5cytsLV26VJMmTVKjRo1cxmNjY7V79+7z3s/MmTPVpk0bhYaGKjQ0VAkJCfr444+t7cYYTZgwQdHR0QoMDFRiYqK2bt3qso+ioiKNHDlS4eHhCg4OVu/evbVv3z6Xmvz8fCUnJ8vpdMrpdCo5OVlHjhy58MYBAAAukFth6/jx4y4rWmUOHz6sgICA895Po0aNNHHiRH311Vf66quvdOedd+qee+6xAtXkyZM1depUzZgxQ+vXr1dUVJS6du3qci+vlJQULVq0SAsWLNDnn3+uY8eOKSkpSSUlJVZN//79lZ2drczMTGVmZio7O1vJycnutA4AAHBBHMaNs9p79eqlm2++WS+88IJCQkK0adMmNW7cWP369VNpaanef/99tydUv359TZkyRUOGDFF0dLRSUlL0zDPPSPptFSsyMlKTJk3SsGHDVFBQoKuuukpvvfWW+vbtK0k6cOCAYmJi9NFHH6l79+7atm2bWrVqpbVr16pdu3aSpLVr1yohIUHfffed9dmO51JYWCin06mCggKFhoa63R+8w7SsHZ6egounujbz9BQAoEaqCX+/3VrZmjJlimbNmqWePXuquLhYTz/9tOLi4rRq1SpNmjTJrYmUlJRowYIFOn78uBISErRr1y7l5uaqW7duVk1AQIA6duyo1atXS5I2bNigU6dOudRER0crLi7OqlmzZo2cTqcVtCSpffv2cjqdVk1FioqKVFhY6PIAAAC4UG6FrVatWmnTpk265ZZb1LVrVx0/flz333+/vv76a1177bUXtK/NmzerTp06CggI0PDhw7Vo0SK1atVKubm5kqTIyEiX+sjISGtbbm6u/P39XT6jsaKaiIiIcseNiIiwaiqSlpZmnePldDoVExNzQX0BAABIbtzUtGwladasWXruuecuegLNmzdXdna2jhw5ooULF2rQoEFauXKltd3hcLjUG2PKjZ3t7JqK6s+1n7Fjx2rUqFHW88LCQgIXAAC4YBe8suXn56ctW7acM/CcL39/f1133XWKj49XWlqabrjhBr388suKioqSpHKrT3l5edZqV1RUlIqLi5Wfn19lTUUfmn3o0KFyq2ZnCggIsK6SLHsAAABcKLfeRnzwwQeVnp5e3XOR9NuKU1FRkZo2baqoqChlZWVZ24qLi7Vy5Up16NBBktS2bVv5+fm51OTk5GjLli1WTUJCggoKCvTll19aNevWrVNBQYFVAwAAYBe3PhuxuLhYr7/+urKyshQfH1/uMxGnTp16Xvt59tln1bNnT8XExOjo0aNasGCBVqxYoczMTDkcDqWkpCg1NVWxsbGKjY1VamqqgoKC1L9/f0mS0+nU0KFDNXr0aIWFhal+/foaM2aMWrdurS5dukiSWrZsqR49euiRRx7RrFmzJEmPPvqokpKSzvtKRAAAAHddUNjauXOnmjRpoi1btujmm2+WJO3Y4XoJ/IW8vXjw4EElJycrJydHTqdTbdq0UWZmprp27SpJevrpp3Xy5EmNGDFC+fn5ateunZYuXaqQkBBrH9OmTZOvr6/69OmjkydPqnPnzpozZ458fHysmnnz5umJJ56wrlrs3bu3ZsyYcSGtAwAAuOWC7rPl4+OjnJwc6+q+vn376m9/+1uV5z55i5pwnw7UHNxnCwAuDzXh7/cFnbN1di77+OOPdfz48WqdEAAAgDdx6wT5Mm7cfB4AAOCKckFhy+FwlDsnq7puAQEAAOCNLugEeWOMBg8ebH3Y9K+//qrhw4eXuxrxgw8+qL4ZAgAAXMYuKGwNGjTI5fnAgQOrdTIAAADe5oLCVkZGhl3zAAAA8EoXdYI8AAAAqkbYAgAAsBFhCwAAwEaELQAAABsRtgAAAGxE2AIAALARYQsAAMBGhC0AAAAbEbYAAABsRNgCAACwEWELAADARoQtAAAAGxG2AAAAbETYAgAAsBFhCwAAwEaELQAAABsRtgAAAGxE2AIAALARYQsAAMBGhC0AAAAbEbYAAABsRNgCAACwEWELAADARoQtAAAAGxG2AAAAbETYAgAAsBFhCwAAwEaELQAAABsRtgAAAGxE2AIAALARYQsAAMBGhC0AAAAbEbYAAABsRNgCAACwEWELAADARoQtAAAAG3k0bKWlpel3v/udQkJCFBERoXvvvVfbt293qTHGaMKECYqOjlZgYKASExO1detWl5qioiKNHDlS4eHhCg4OVu/evbVv3z6Xmvz8fCUnJ8vpdMrpdCo5OVlHjhyxu0UAAHCF82jYWrlypR577DGtXbtWWVlZOn36tLp166bjx49bNZMnT9bUqVM1Y8YMrV+/XlFRUeratauOHj1q1aSkpGjRokVasGCBPv/8cx07dkxJSUkqKSmxavr376/s7GxlZmYqMzNT2dnZSk5OvqT9AgCAK4/DGGM8PYkyhw4dUkREhFauXKk77rhDxhhFR0crJSVFzzzzjKTfVrEiIyM1adIkDRs2TAUFBbrqqqv01ltvqW/fvpKkAwcOKCYmRh999JG6d++ubdu2qVWrVlq7dq3atWsnSVq7dq0SEhL03XffqXnz5uecW2FhoZxOpwoKChQaGmrfFwGXhWlZOzw9BRdPdW3m6SkAQI1UE/5+16hztgoKCiRJ9evXlyTt2rVLubm56tatm1UTEBCgjh07avXq1ZKkDRs26NSpUy410dHRiouLs2rWrFkjp9NpBS1Jat++vZxOp1VztqKiIhUWFro8AAAALlSNCVvGGI0aNUq33Xab4uLiJEm5ubmSpMjISJfayMhIa1tubq78/f1Vr169KmsiIiLKHTMiIsKqOVtaWpp1fpfT6VRMTMzFNQgAAK5INSZsPf7449q0aZPmz59fbpvD4XB5bowpN3a2s2sqqq9qP2PHjlVBQYH12Lt37/m0AQAA4KJGhK2RI0dqyZIlWr58uRo1amSNR0VFSVK51ae8vDxrtSsqKkrFxcXKz8+vsubgwYPljnvo0KFyq2ZlAgICFBoa6vIAAAC4UB4NW8YYPf744/rggw/02WefqWnTpi7bmzZtqqioKGVlZVljxcXFWrlypTp06CBJatu2rfz8/FxqcnJytGXLFqsmISFBBQUF+vLLL62adevWqaCgwKoBAACwg68nD/7YY4/pnXfe0b/+9S+FhIRYK1hOp1OBgYFyOBxKSUlRamqqYmNjFRsbq9TUVAUFBal///5W7dChQzV69GiFhYWpfv36GjNmjFq3bq0uXbpIklq2bKkePXrokUce0axZsyRJjz76qJKSks7rSkQAAAB3eTRszZw5U5KUmJjoMp6RkaHBgwdLkp5++mmdPHlSI0aMUH5+vtq1a6elS5cqJCTEqp82bZp8fX3Vp08fnTx5Up07d9acOXPk4+Nj1cybN09PPPGEddVi7969NWPGDHsbBAAAV7wadZ+tmqwm3KcDNUdNu89WdeF+XQC8TU34+10jTpAHAADwVoQtAAAAGxG2AAAAbETYAgAAsBFhCwAAwEaELQAAABsRtgAAAGxE2AIAALARYQsAAMBGhC0AAAAbEbYAAABsRNgCAACwEWELAADARoQtAAAAGxG2AAAAbETYAgAAsBFhCwAAwEaELQAAABsRtgAAAGxE2AIAALARYQsAAMBGvp6eAHAlab/nNbdet/bqR6t5JgCAS4WVLQAAABsRtgAAAGxE2AIAALAR52wBbnD33CsAwJWHlS0AAAAbEbYAAABsRNgCAACwEWELAADARoQtAAAAGxG2AAAAbETYAgAAsBFhCwAAwEaELQAAABsRtgAAAGxE2AIAALARYQsAAMBGhC0AAAAbEbYAAABsRNgCAACwEWELAADARh4NW6tWrdLdd9+t6OhoORwOLV682GW7MUYTJkxQdHS0AgMDlZiYqK1bt7rUFBUVaeTIkQoPD1dwcLB69+6tffv2udTk5+crOTlZTqdTTqdTycnJOnLkiM3dAQAASL6ePPjx48d1ww036KGHHtLvf//7ctsnT56sqVOnas6cOWrWrJlefPFFde3aVdu3b1dISIgkKSUlRR9++KEWLFigsLAwjR49WklJSdqwYYN8fHwkSf3799e+ffuUmZkpSXr00UeVnJysDz/88NI1C1wGpmXtqJb9PNW1WbXsBwC8gUfDVs+ePdWzZ88KtxljNH36dI0bN07333+/JOnNN99UZGSk3nnnHQ0bNkwFBQVKT0/XW2+9pS5dukiS3n77bcXExGjZsmXq3r27tm3bpszMTK1du1bt2rWTJM2ePVsJCQnavn27mjdvfmmaBQAAV6Qae87Wrl27lJubq27dulljAQEB6tixo1avXi1J2rBhg06dOuVSEx0drbi4OKtmzZo1cjqdVtCSpPbt28vpdFo1AAAAdvHoylZVcnNzJUmRkZEu45GRkdq9e7dV4+/vr3r16pWrKXt9bm6uIiIiyu0/IiLCqqlIUVGRioqKrOeFhYXuNQIAAK5oNXZlq4zD4XB5bowpN3a2s2sqqj/XftLS0qwT6p1Op2JiYi5w5gAAADU4bEVFRUlSudWnvLw8a7UrKipKxcXFys/Pr7Lm4MGD5fZ/6NChcqtmZxo7dqwKCgqsx969ey+qHwAAcGWqsWGradOmioqKUlZWljVWXFyslStXqkOHDpKktm3bys/Pz6UmJydHW7ZssWoSEhJUUFCgL7/80qpZt26dCgoKrJqKBAQEKDQ01OUBAABwoTx6ztaxY8f0ww8/WM937dql7Oxs1a9fX1dffbVSUlKUmpqq2NhYxcbGKjU1VUFBQerfv78kyel0aujQoRo9erTCwsJUv359jRkzRq1bt7auTmzZsqV69OihRx55RLNmzZL0260fkpKSuBIRAADYzqNh66uvvlKnTp2s56NGjZIkDRo0SHPmzNHTTz+tkydPasSIEcrPz1e7du20dOlS6x5bkjRt2jT5+vqqT58+OnnypDp37qw5c+ZY99iSpHnz5umJJ56wrlrs3bu3ZsyYcYm6BAAAVzKHMcZ4ehKXg8LCQjmdThUUFPCWIrQmfcwlPd7aqx+9pMe7WNzUFEBNURP+ftfYc7YAAAC8AWELAADARoQtAAAAGxG2AAAAbETYAgAAsFGN/WxEAP9f+z2vufW6y+0qRgDwRqxsAQAA2IiwBQAAYCPCFgAAgI0IWwAAADbiBHkA1W5a1o5q2Q8f+wPAG7CyBQAAYCPCFgAAgI0IWwAAADYibAEAANiIsAUAAGAjwhYAAICNCFsAAAA2ImwBAADYiLAFAABgI8IWAACAjQhbAAAANuKzEQHUWHzGIgBvwMoWAACAjQhbAAAANiJsAQAA2IiwBQAAYCPCFgAAgI0IWwAAADYibAEAANiI+2wB8HrcrwuAJ7GyBQAAYCPCFgAAgI14GxHwYu33vOb2a9de/Wg1zgQArlyELQAVcjeoEdIAwBVvIwIAANiIsAUAAGAjwhYAAICNOGcLAM4T9+sC4A5WtgAAAGzEyhaAasVVjADgipUtAAAAG11RK1uvvPKKpkyZopycHF1//fWaPn26br/9dk9PC4CurBUxzv0CrixXTNh69913lZKSoldeeUW33nqrZs2apZ49e+rbb7/V1Vdf7enpAXDTxdwl3x2XY7g7F8IfYK8rJmxNnTpVQ4cO1cMPPyxJmj59uj755BPNnDlTaWlpHp4dAFy46gpJAOx1RYSt4uJibdiwQX/+859dxrt166bVq1d7aFYALkeXeiVNunxW02pa+GOlDTXFFRG2Dh8+rJKSEkVGRrqMR0ZGKjc3t8LXFBUVqaioyHpeUFAgSSosLLRvorDdPz77oVr287uTRecuAqpJ6+1/9/QUbLW+0UNuve53+zKq3L5se/Ue72I9dud11bKf6vo9Vl3zqenK/m4bYzw2hysibJVxOBwuz40x5cbKpKWl6bnnnis3HhMTY8vcAODKNcPLj/ebZz1y1MrVtPnY7ejRo3I6nR459hURtsLDw+Xj41NuFSsvL6/caleZsWPHatSoUdbz0tJS/fLLLwoLC6s0oFWnwsJCxcTEaO/evQoNDbX9eJ5Cn97lSujzSuhRok9vcyX3aYzR0aNHFR0d7bF5XRFhy9/fX23btlVWVpbuu+8+azwrK0v33HNPha8JCAhQQECAy1jdunXtnGaFQkNDvfofRhn69C5XQp9XQo8SfXqbK7VPT61olbkiwpYkjRo1SsnJyYqPj1dCQoJee+017dmzR8OHD/f01AAAgBe7YsJW37599fPPP+v5559XTk6O4uLi9NFHH6lx48aenhoAAPBiV0zYkqQRI0ZoxIgRnp7GeQkICND48ePLvZXpbejTu1wJfV4JPUr06W3o07McxpPXQgIAAHg5PogaAADARoQtAAAAGxG2AAAAbETYAgAAsBFhq5r89NNPGjp0qJo2barAwEBde+21Gj9+vIqLi13q9uzZo7vvvlvBwcEKDw/XE088Ua5m8+bN6tixowIDA9WwYUM9//zz5T7TaeXKlWrbtq1q166ta665Rq+++mq5OS1cuFCtWrVSQECAWrVqpUWLFpWreeWVV9S0aVPVrl1bbdu21X//+99z9vrXv/5VHTp0UFBQUKU3evWGPquLJ499plWrVunuu+9WdHS0HA6HFi9e7LLdGKMJEyYoOjpagYGBSkxM1NatW11qioqKNHLkSIWHhys4OFi9e/fWvn37XGry8/OVnJwsp9Mpp9Op5ORkHTlyxKWmun4+KpKWlqbf/e53CgkJUUREhO69915t3+76IXne0OvMmTPVpk0b6+aNCQkJ+vjjj72qx4qkpaXJ4XAoJSXFq3qdMGGCHA6HyyMqKsqreiyzf/9+DRw4UGFhYQoKCtKNN96oDRs2eGWvZzaFavDxxx+bwYMHm08++cT8+OOP5l//+peJiIgwo0ePtmpOnz5t4uLiTKdOnczGjRtNVlaWiY6ONo8//rhVU1BQYCIjI02/fv3M5s2bzcKFC01ISIj53//9X6tm586dJigoyDz55JPm22+/NbNnzzZ+fn7m/ffft2pWr15tfHx8TGpqqtm2bZtJTU01vr6+Zu3atVbNggULjJ+fn5k9e7b59ttvzZNPPmmCg4PN7t27q+z1//yf/2OmTp1qRo0aZZxOZ7nt3tJndfDksc/20UcfmXHjxpmFCxcaSWbRokUu2ydOnGhCQkLMwoULzebNm03fvn1NgwYNTGFhoVUzfPhw07BhQ5OVlWU2btxoOnXqZG644QZz+vRpq6ZHjx4mLi7OrF692qxevdrExcWZpKQka3t1/XxUpnv37iYjI8Ns2bLFZGdnm169epmrr77aHDt2zKt6XbJkifnPf/5jtm/fbrZv326effZZ4+fnZ7Zs2eI1PZ7tyy+/NE2aNDFt2rQxTz75pDXuDb2OHz/eXH/99SYnJ8d65OXleVWPxhjzyy+/mMaNG5vBgwebdevWmV27dplly5aZH374wet6PRNhy0aTJ082TZs2tZ5/9NFHplatWmb//v3W2Pz5801AQIApKCgwxhjzyiuvGKfTaX799VerJi0tzURHR5vS0lJjjDFPP/20adGihcuxhg0bZtq3b28979Onj+nRo4dLTffu3U2/fv2s57fccosZPny4S02LFi3Mn//85/PqLyMjo8Kw5W19XgxPHrsqZ4et0tJSExUVZSZOnGiN/frrr8bpdJpXX33VGGPMkSNHjJ+fn1mwYIFVs3//flOrVi2TmZlpjDHm22+/NZJcwu6aNWuMJPPdd98ZY6rv5+N85eXlGUlm5cqVXt9rvXr1zOuvv+6VPR49etTExsaarKws07FjRytseUuv48ePNzfccEOF27ylR2OMeeaZZ8xtt91W6XZv6vVMvI1oo4KCAtWvX996vmbNGsXFxbl8GGb37t1VVFRkLaGuWbNGHTt2dLkhW/fu3XXgwAH99NNPVk23bt1cjtW9e3d99dVXOnXqVJU1q1evliQVFxdrw4YN5Wq6detm1bjrSunzXDx57Au1a9cu5ebmusw1ICBAHTt2tOa6YcMGnTp1yqUmOjpacXFxVs2aNWvkdDrVrl07q6Z9+/ZyOp0uNdXx83G+CgoKJMn6t+iNvZaUlGjBggU6fvy4EhISvLLHxx57TL169VKXLl1cxr2p1++//17R0dFq2rSp+vXrp507d3pdj0uWLFF8fLz+8Ic/KCIiQjfddJNmz55tbfemXs9E2LLJjz/+qL///e8un72Ym5uryMhIl7p69erJ399fubm5ldaUPT9XzenTp3X48OEqa8r2cfjwYZWUlFRZ464rpc9z8eSxL1TZfKqaa25urvz9/VWvXr0qayIiIsrtPyIiosrvqzs/H+fDGKNRo0bptttuU1xcnNf1unnzZtWpU0cBAQEaPny4Fi1apFatWnlVj5K0YMECbdy4UWlpaeW2eUuv7dq109y5c/XJJ59o9uzZys3NVYcOHfTzzz97TY+StHPnTs2cOVOxsbH65JNPNHz4cD3xxBOaO3euy+u9odczXVEf1+OOCRMm6LnnnquyZv369YqPj7eeHzhwQD169NAf/vAHPfzwwy61Doej3OuNMS7jZ9eY/3ciXnXUnD1W9vzsPiua59l9VqWm9llVjV08eewL5c5cz/V9ra6air735/L4449r06ZN+vzzz8tt84ZemzdvruzsbB05ckQLFy7UoEGDtHLlyir3e7n1uHfvXj355JNaunSpateuXWnd5d5rz549rf9u3bq1EhISdO211+rNN99U+/btK93v5dSjJJWWlio+Pl6pqamSpJtuuklbt27VzJkz9eCDD1a5/8ut1zOxsnUOjz/+uLZt21blo+z/mKXfglanTp2UkJCg1157zWVfUVFR5ZJwfn6+Tp06ZSXlimry8vIk6Zw1vr6+CgsLq7KmbB/h4eHy8fGxasr6HDhwoOLj48/ZZ1Vqcp8V1djFk8e+UGVXPVU116ioKBUXFys/P7/KmoMHD5bb/6FDh6r8vrrz83EuI0eO1JIlS7R8+XI1atTIK3v19/fXddddp/j4eKWlpemGG27Qyy+/7FU9btiwQXl5eWrbtq18fX3l6+urlStX6m9/+5t8fX0rXWW4HHs9U3BwsFq3bq3vv//eq76fDRo0UKtWrVzGWrZsqT179lj79pZez0TYOofw8HC1aNGiykfZ/23t379fiYmJuvnmm5WRkaFatVy/vAkJCdqyZYtycnKssaVLlyogIEBt27a1alatWuVy6enSpUsVHR2tJk2aWDVZWVku+166dKni4+Pl5+dXZU2HDh0k/fZLum3btlZNWZ8bNmxQly5dquzzXGpyn2WysrKsGrt48tgXqmnTpoqKinKZa3FxsVauXGnNtW3btvLz83OpycnJ0ZYtW6yahIQEFRQU6Msvv7Rq1q1bp4KCApea6vj5qIwxRo8//rg++OADffbZZ2ratKnX9lpR70VFRV7VY+fOnbV582ZlZ2dbj/j4eA0YMEDZ2dm65pprvKbXMxUVFWnbtm1q0KCBV30/b7311nK3YtmxY4caN24syYv/fZ73qfSo0v79+811111n7rzzTrNv3z6Xy3fLlF1m2rlzZ7Nx40azbNky06hRI5fLTI8cOWIiIyPNAw88YDZv3mw++OADExoaWuEtEZ566inz7bffmvT09HK3RPjiiy+Mj4+PmThxotm2bZuZOHFipbdESE9PN99++61JSUkxwcHB5qeffqqy1927d5uvv/7aPPfcc6ZOnTrm66+/Nl9//bU5evSoV/VZHTx57LMdPXrU+l5JMlOnTjVff/21dRuKiRMnGqfTaT744AOzefNm88ADD1R4uXWjRo3MsmXLzMaNG82dd95Z4eXWbdq0MWvWrDFr1qwxrVu3rvBy64v9+ajMH//4R+N0Os2KFStc/h2eOHHCqvGGXseOHWtWrVpldu3aZTZt2mSeffZZU6tWLbN06VKv6bEyZ16N6C29jh492qxYscLs3LnTrF271iQlJZmQkBDrd4U39GjMb7fv8PX1NX/961/N999/b+bNm2eCgoLM22+/7VXfz7MRtqpJRkaGkVTh40y7d+82vXr1MoGBgaZ+/frm8ccfd7mk1BhjNm3aZG6//XYTEBBgoqKizIQJE8pdYrpixQpz0003GX9/f9OkSRMzc+bMcnN67733TPPmzY2fn59p0aKFWbhwYbmaf/zjH6Zx48bG39/f3Hzzzdbl8VUZNGhQhX0uX77cq/qsLp489pmWL19e4fdt0KBBxpjfLrkeP368iYqKMgEBAeaOO+4wmzdvdtnHyZMnzeOPP27q169vAgMDTVJSktmzZ49Lzc8//2wGDBhgQkJCTEhIiBkwYIDJz893qamun4+KVPbvMCMjw6rxhl6HDBli/VxdddVVpnPnzlbQ8pYeK3N22PKGXsvuJeXn52eio6PN/fffb7Zu3epVPZb58MMPTVxcnAkICDAtWrQwr732mst2b+q1jMMYN27hCwAAgPPCOVsAAAA2ImwBAADYiLAFAABgI8IWAACAjQhbAAAANiJsAQAA2IiwBQAAYCPCFgAAgI0IWwA8YvDgwXI4HNYjLCxMPXr00KZNm6wah8OhxYsXV/r8TCtWrJDD4dCRI0fcntO+ffvk7++vFi1aVLi9bK5r1651GS8qKlJYWJgcDodWrFihOXPmuPRW0WPFihXWa8eNG6fGjRsrICBA1157rd544w23ewBQ8xC2AHhMjx49lJOTo5ycHH366afy9fVVUlKSx+YzZ84c9enTRydOnNAXX3xRYU1MTIwyMjJcxhYtWqQ6depYz/v27Wv1lZOTo4SEBD3yyCMuY2UfhtunTx99+umnSk9P1/bt2zV//vxKwx6Ay5OvpycA4MoVEBCgqKgoSVJUVJSeeeYZ3XHHHTp06JCuuuqqSzoXY4wyMjL0yiuvqFGjRkpPT9ett95arm7QoEH629/+punTpyswMFCS9MYbb2jQoEF64YUXJEmBgYHWNkny9/dXUFCQ1WuZzMxMrVy5Ujt37lT9+vUlSU2aNLGpQwCewsoWgBrh2LFjmjdvnq677jqFhYVd8uMvX75cJ06cUJcuXZScnKx//vOfOnr0aLm6tm3bqmnTplq4cKEkae/evVq1apWSk5Mv+JhLlixRfHy8Jk+erIYNG6pZs2YaM2aMTp48edH9AKg5CFsAPObf//636tSpozp16igkJERLlizRu+++q1q1Lv2vpvT0dPXr108+Pj66/vrrdd111+ndd9+tsPahhx6yzqvKyMjQXXfd5dZK3M6dO/X5559ry5YtWrRokaZPn673339fjz322EX1AqBmIWwB8JhOnTopOztb2dnZWrdunbp166aePXtq9+7dl3QeR44c0QcffKCBAwdaYwMHDqz0RPWBAwdqzZo12rlzp+bMmaMhQ4a4ddzS0lI5HA7NmzdPt9xyi+666y5NnTpVc+bMYXUL8CKcswXAY4KDg3XddddZz9u2bSun06nZs2frxRdfvGTzeOedd/Trr7+qXbt21pgxRqWlpfr222/VqlUrl/qwsDAlJSVp6NCh+vXXX9WzZ88K33I8lwYNGqhhw4ZyOp3WWMuWLWWM0b59+xQbG+t+UwBqDFa2ANQYDodDtWrVuuSrOunp6Ro9erS1ypadna1vvvlGnTp1qnR1a8iQIVqxYoUefPBB+fj4uHXcW2+9VQcOHNCxY8essR07dqhWrVpq1KiRW/sEUPOwsgXAY4qKipSbmytJys/P14wZM3Ts2DHdfffdlb5m165dys7Odhk7c3Vs8+bNCgkJcdl+4403Vrq/7Oxsbdy4UfPmzSt3y4UHHnhA48aNU1pamvz8/Fy29ejRQ4cOHVJoaGhVLVapf//+euGFF/TQQw/pueee0+HDh/WnP/1JQ4YMcbmaEcDljbAFwGMyMzPVoEEDSVJISIhatGih9957T4mJiZW+ZtSoUeXGli9fbv33HXfcUW67MabS/aWnp6tVq1YV3tvq3nvv1R//+Ed9+OGHuv/++122ORwOhYeHV7rf81GnTh1lZWVp5MiRio+PV1hYmPr06XNJ30IFYD+Hqeq3EAAAAC4K52wBAADYiLAFwOuV3curosd///tfT08PgJfjbUQAXu+HH36odFvDhg05GR2ArQhbAAAANuJtRAAAABsRtgAAAGxE2AIAALARYQsAAMBGhC0AAAAbEbYAAABsRNgCAACwEWELAADARv8Xka8W+bpEI/MAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_cols = [\"LIMIT_BAL\", \"EDUCATION\", \"BILL_AMT6\"]\n",
    "\n",
    "# Copied from HW2\n",
    "def plot_feature_against_target(feat):\n",
    "    ax = train_df.groupby(\"default.payment.next.month\")[feat].plot.hist(bins=25, alpha=0.5, legend=True)\n",
    "    plt.xlabel(feat)\n",
    "    plt.title(\"Histogram of \" + feat)\n",
    "    plt.show()\n",
    "for feat in plot_cols:\n",
    "    plot_feature_against_target(feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With higher credit and education, one is less likely to have to pay for default payment. Higher bill is likely to default. LIMIT_BAL and BILL_AMT need to be scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "default.payment.next.month\n",
       "0    23364\n",
       "1     6636\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"default.payment.next.month\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good metrics for this model would be to combine precision and recall which is F1 score. Since the dataset is inbalanced, it is good to use F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 4. Preprocessing and transformations <a name=\"5\"></a>\n",
    "<hr>\n",
    "\n",
    "_points: 10_\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Identify different feature types and the transformations you would apply on each feature type. \n",
    "2. Define a column transformer, if necessary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_4\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature | Transformation | Explanation |\n",
    "|---------|----------------|-------------|\n",
    "| ID | Drop | Useless column |\n",
    "| LIMIT_BAL | Scaling | Values have a very big range |\n",
    "| SEX | One-hot Encoding | Binary categorical column |\n",
    "| EDUCATION | Ordinal Encoding | Order from 6 to 1. Should change all 0's to most frequently seen value |\n",
    "| MARRIAGE | One-hot Encoding | Categorical column. 0 is unknown, just keep it |\n",
    "| AGE | Scaling | Values have a big range |\n",
    "| PAY_0 to PAY_6 | Ordinal Encoding | Order from 8 to -2 |\n",
    "| BILL_AMT1 to BILL_AMT6 | Scaling | Values have a big range |\n",
    "| PAY_AMT1 to PAY_AMT6 | Scaling | Values have a big range |\n",
    "| default.payment.next.month | One-hot Encoding | Categorical column |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns\n",
    "\n",
    "categorical_cols_y = \"default.payment.next.month\"\n",
    "\n",
    "drop_cols = [\"ID\"]\n",
    "\n",
    "numeric_cols = [\"LIMIT_BAL\", \"AGE\", \"BILL_AMT1\", \"BILL_AMT2\", \"BILL_AMT3\", \"BILL_AMT4\", \"BILL_AMT5\", \"BILL_AMT6\", \n",
    "                \"PAY_AMT1\", \"PAY_AMT2\", \"PAY_AMT3\", \"PAY_AMT4\", \"PAY_AMT5\", \"PAY_AMT6\"]\n",
    "\n",
    "categorical_cols_X = [\"SEX\", \"MARRIAGE\"]\n",
    "\n",
    "ordinal_cols_pay = [\"PAY_0\", \"PAY_2\", \"PAY_3\", \"PAY_4\", \"PAY_5\", \"PAY_6\"]\n",
    "pay_ordering = [[-2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8]] * len(ordinal_cols_pay)\n",
    "\n",
    "mode = dataset['EDUCATION'].mode()[0]\n",
    "X_train['EDUCATION'] = X_train['EDUCATION'].replace(0, mode)\n",
    "X_test['EDUCATION'] = X_test['EDUCATION'].replace(0, mode)\n",
    "ordinal_cols_edu = [\"EDUCATION\"]\n",
    "edu_ordering = [[1, 2, 3, 4, 5, 6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformers\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(drop=\"if_binary\", handle_unknown=\"ignore\")\n",
    "ordinal_transformer_pay = OrdinalEncoder(categories = pay_ordering)\n",
    "ordinal_transformer_edu = OrdinalEncoder(categories = edu_ordering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Transformers Preprocessor\n",
    "preprocessor_X = make_column_transformer(\n",
    "    (numeric_transformer, numeric_cols),\n",
    "    (categorical_transformer, categorical_cols_X),\n",
    "    (ordinal_transformer_pay, ordinal_cols_pay),\n",
    "    (ordinal_transformer_edu, ordinal_cols_edu),\n",
    "    (\"drop\", drop_cols),\n",
    "    remainder=\"passthrough\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.32729199,  0.93990457,  0.43392148, ...,  2.        ,\n",
       "         2.        ,  0.        ],\n",
       "       [ 0.24967276, -0.15465623,  2.09451429, ...,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [-0.67400086, -1.03030486,  0.37707167, ...,  2.        ,\n",
       "         2.        ,  1.        ],\n",
       "       ...,\n",
       "       [-0.67400086, -0.04520015, -0.64475849, ...,  1.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [-0.67400086, -0.92084878, -0.66674078, ...,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [-0.52005526, -0.26411231,  0.32957689, ...,  2.        ,\n",
       "         2.        ,  0.        ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing\n",
    "transformed_X_train = preprocessor_X.fit_transform(X_train)\n",
    "transformed_X_test = preprocessor_X.transform(X_test)\n",
    "transformed_X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 5. Baseline model <a name=\"6\"></a>\n",
    "<hr>\n",
    "\n",
    "_points: 2_\n",
    "\n",
    "**Your tasks:**\n",
    "1. Try `scikit-learn`'s baseline model and report results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_5\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORING = \"f1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean validation score 0.000\n",
      "Mean training score 0.000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.035622</td>\n",
       "      <td>0.009946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.038923</td>\n",
       "      <td>0.012079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.036865</td>\n",
       "      <td>0.008165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.053705</td>\n",
       "      <td>0.007744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.035787</td>\n",
       "      <td>0.010532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.039436</td>\n",
       "      <td>0.006608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.030996</td>\n",
       "      <td>0.010063</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.034886</td>\n",
       "      <td>0.010857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.041251</td>\n",
       "      <td>0.008189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.033939</td>\n",
       "      <td>0.007877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  0.035622    0.009946         0.0          0.0\n",
       "1  0.038923    0.012079         0.0          0.0\n",
       "2  0.036865    0.008165         0.0          0.0\n",
       "3  0.053705    0.007744         0.0          0.0\n",
       "4  0.035787    0.010532         0.0          0.0\n",
       "5  0.039436    0.006608         0.0          0.0\n",
       "6  0.030996    0.010063         0.0          0.0\n",
       "7  0.034886    0.010857         0.0          0.0\n",
       "8  0.041251    0.008189         0.0          0.0\n",
       "9  0.033939    0.007877         0.0          0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pipeline\n",
    "pipe_dummy = make_pipeline(preprocessor_X, DummyClassifier(random_state=76))\n",
    "pipe_dummy.fit(X_train, y_train)\n",
    "\n",
    "scores = cross_validate(pipe_dummy, X_train, y_train, cv=10, scoring=SCORING, return_train_score=True)\n",
    "print(\"Mean validation score %0.3f\" % (np.mean(scores[\"test_score\"])))\n",
    "print(\"Mean training score %0.3f\" % (np.mean(scores[\"train_score\"])))\n",
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1 score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculation</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sklearn</th>\n",
       "      <td>0.780333</td>\n",
       "      <td>0.219667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             accuracy     error  precision  recall  f1 score\n",
       "calculation                                                 \n",
       "sklearn      0.780333  0.219667        1.0     0.0       0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    \"calculation\": [],\n",
    "    \"accuracy\": [],\n",
    "    \"error\": [],\n",
    "    \"precision\": [],\n",
    "    \"recall\": [],\n",
    "    \"f1 score\": [],\n",
    "}\n",
    "data[\"accuracy\"].append(accuracy_score(y_test, pipe_dummy.predict(X_test)))\n",
    "data[\"error\"].append(1 - accuracy_score(y_test, pipe_dummy.predict(X_test)))\n",
    "data[\"precision\"].append(\n",
    "    precision_score(y_test, pipe_dummy.predict(X_test), zero_division=1)\n",
    ")\n",
    "data[\"recall\"].append(recall_score(y_test, pipe_dummy.predict(X_test)))\n",
    "data[\"f1 score\"].append(f1_score(y_test, pipe_dummy.predict(X_test)))\n",
    "data[\"calculation\"].append(\"sklearn\")\n",
    "df = pd.DataFrame(data)\n",
    "df.set_index([\"calculation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DummyClassifier` seems to be giving perfect precision while having 0 recall. This results in a 0 f1-score.\n",
    "This is because `DummyClassifier` is predicting all negative results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 6. Linear models <a name=\"7\"></a>\n",
    "<hr>\n",
    "\n",
    "_points 10_\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Try a linear model as a first real attempt. \n",
    "2. Carry out hyperparameter tuning to explore different values for the complexity hyperparameter. \n",
    "3. Report cross-validation scores along with standard deviation. \n",
    "4. Summarize your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_6\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean validation score 0.355\n",
      "Mean training score 0.358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.126316</td>\n",
       "      <td>0.004548</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.361881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.112378</td>\n",
       "      <td>0.009968</td>\n",
       "      <td>0.365971</td>\n",
       "      <td>0.356695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.116444</td>\n",
       "      <td>0.008511</td>\n",
       "      <td>0.379585</td>\n",
       "      <td>0.352708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.113817</td>\n",
       "      <td>0.010312</td>\n",
       "      <td>0.384000</td>\n",
       "      <td>0.354458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.109870</td>\n",
       "      <td>0.007006</td>\n",
       "      <td>0.326797</td>\n",
       "      <td>0.361527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.114819</td>\n",
       "      <td>0.010209</td>\n",
       "      <td>0.393701</td>\n",
       "      <td>0.356120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.109602</td>\n",
       "      <td>0.007558</td>\n",
       "      <td>0.392971</td>\n",
       "      <td>0.353026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.117615</td>\n",
       "      <td>0.007684</td>\n",
       "      <td>0.332795</td>\n",
       "      <td>0.365385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.104113</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.352751</td>\n",
       "      <td>0.356400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.129896</td>\n",
       "      <td>0.009586</td>\n",
       "      <td>0.309446</td>\n",
       "      <td>0.365936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  0.126316    0.004548    0.310000     0.361881\n",
       "1  0.112378    0.009968    0.365971     0.356695\n",
       "2  0.116444    0.008511    0.379585     0.352708\n",
       "3  0.113817    0.010312    0.384000     0.354458\n",
       "4  0.109870    0.007006    0.326797     0.361527\n",
       "5  0.114819    0.010209    0.393701     0.356120\n",
       "6  0.109602    0.007558    0.392971     0.353026\n",
       "7  0.117615    0.007684    0.332795     0.365385\n",
       "8  0.104113    0.009014    0.352751     0.356400\n",
       "9  0.129896    0.009586    0.309446     0.365936"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pipeline\n",
    "pipe_lr = make_pipeline(preprocessor_X, LogisticRegression(random_state=76))\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "logisticScores = cross_validate(pipe_lr, X_train, y_train, cv=10, scoring=SCORING, return_train_score=True)\n",
    "print(\"Mean validation score %0.3f\" % (np.mean(logisticScores[\"test_score\"])))\n",
    "print(\"Mean training score %0.3f\" % (np.mean(logisticScores[\"train_score\"])))\n",
    "pd.DataFrame(logisticScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>mean_train_scores</th>\n",
       "      <th>mean_cv_scores</th>\n",
       "      <th>std_cv_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.043931</td>\n",
       "      <td>0.044300</td>\n",
       "      <td>0.015553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.267119</td>\n",
       "      <td>0.266376</td>\n",
       "      <td>0.030952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.344808</td>\n",
       "      <td>0.345605</td>\n",
       "      <td>0.022672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.357114</td>\n",
       "      <td>0.354991</td>\n",
       "      <td>0.020422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.358333</td>\n",
       "      <td>0.356851</td>\n",
       "      <td>0.019441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.0000</td>\n",
       "      <td>0.358458</td>\n",
       "      <td>0.358177</td>\n",
       "      <td>0.019594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100.0000</td>\n",
       "      <td>0.358398</td>\n",
       "      <td>0.357907</td>\n",
       "      <td>0.019889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000.0000</td>\n",
       "      <td>0.358435</td>\n",
       "      <td>0.358177</td>\n",
       "      <td>0.019594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10000.0000</td>\n",
       "      <td>0.358481</td>\n",
       "      <td>0.357907</td>\n",
       "      <td>0.019889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100000.0000</td>\n",
       "      <td>0.358479</td>\n",
       "      <td>0.358177</td>\n",
       "      <td>0.019594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             C  mean_train_scores  mean_cv_scores  std_cv_scores\n",
       "0       0.0001           0.043931        0.044300       0.015553\n",
       "1       0.0010           0.267119        0.266376       0.030952\n",
       "2       0.0100           0.344808        0.345605       0.022672\n",
       "3       0.1000           0.357114        0.354991       0.020422\n",
       "4       1.0000           0.358333        0.356851       0.019441\n",
       "5      10.0000           0.358458        0.358177       0.019594\n",
       "6     100.0000           0.358398        0.357907       0.019889\n",
       "7    1000.0000           0.358435        0.358177       0.019594\n",
       "8   10000.0000           0.358481        0.357907       0.019889\n",
       "9  100000.0000           0.358479        0.358177       0.019594"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lecture 7\n",
    "scores_dict = {\n",
    "    \"C\": 10.0 ** np.arange(-4, 6, 1),\n",
    "    \"mean_train_scores\": [],\n",
    "    \"mean_cv_scores\": [],\n",
    "    \"std_cv_scores\": [],\n",
    "}\n",
    "\n",
    "for C in scores_dict[\"C\"]:\n",
    "    pipe_lr_tuning = make_pipeline(preprocessor_X, LogisticRegression(C=C))\n",
    "    scores = cross_validate(pipe_lr_tuning, X_train, y_train, scoring=SCORING, return_train_score=True, return_estimator=True)\n",
    "    scores_dict[\"mean_train_scores\"].append(scores[\"train_score\"].mean())\n",
    "    scores_dict[\"mean_cv_scores\"].append(scores[\"test_score\"].mean())\n",
    "    scores_dict[\"std_cv_scores\"].append(scores[\"test_score\"].std())\n",
    "\n",
    "results_df = pd.DataFrame(scores_dict)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best score appears with $C = 10, 1000, 100000$ with $mean = 0.358177$, $std = 0.019594$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 7. Different models <a name=\"8\"></a>\n",
    "<hr>\n",
    "\n",
    "_points: 12_\n",
    "\n",
    "**Your tasks:**\n",
    "1. Try at least 3 other models aside from a linear model. One of these models should be a tree-based ensemble model. \n",
    "2. Summarize your results in terms of overfitting/underfitting and fit and score times. Can you beat a linear model? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_7\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean validation score 0.455\n",
      "Mean training score 0.468\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.385656</td>\n",
       "      <td>2.758621</td>\n",
       "      <td>0.451051</td>\n",
       "      <td>0.465291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.539899</td>\n",
       "      <td>3.162435</td>\n",
       "      <td>0.481534</td>\n",
       "      <td>0.463319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.564452</td>\n",
       "      <td>3.340264</td>\n",
       "      <td>0.443969</td>\n",
       "      <td>0.472202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.519089</td>\n",
       "      <td>3.199998</td>\n",
       "      <td>0.449390</td>\n",
       "      <td>0.468494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.097055</td>\n",
       "      <td>3.077603</td>\n",
       "      <td>0.448519</td>\n",
       "      <td>0.471886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  8.385656    2.758621    0.451051     0.465291\n",
       "1  8.539899    3.162435    0.481534     0.463319\n",
       "2  9.564452    3.340264    0.443969     0.472202\n",
       "3  9.519089    3.199998    0.449390     0.468494\n",
       "4  9.097055    3.077603    0.448519     0.471886"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model: SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pipe_svm = make_pipeline(preprocessor_X, SVC(random_state=76))\n",
    "svmScores = cross_validate(pipe_svm, X_train, y_train, scoring=SCORING, return_train_score=True)\n",
    "print(\"Mean validation score %0.3f\" % (np.mean(svmScores[\"test_score\"])))\n",
    "print(\"Mean training score %0.3f\" % (np.mean(svmScores[\"train_score\"])))\n",
    "pd.DataFrame(svmScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean validation score 0.479\n",
      "Mean training score 0.999\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.012622</td>\n",
       "      <td>0.088094</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.999597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.200471</td>\n",
       "      <td>0.085725</td>\n",
       "      <td>0.490970</td>\n",
       "      <td>0.998927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.589744</td>\n",
       "      <td>0.079447</td>\n",
       "      <td>0.478759</td>\n",
       "      <td>0.999195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.105357</td>\n",
       "      <td>0.080298</td>\n",
       "      <td>0.466759</td>\n",
       "      <td>0.998793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.683739</td>\n",
       "      <td>0.080029</td>\n",
       "      <td>0.487214</td>\n",
       "      <td>0.998927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fit_time  score_time  test_score  train_score\n",
       "0  10.012622    0.088094    0.470588     0.999597\n",
       "1   9.200471    0.085725    0.490970     0.998927\n",
       "2   9.589744    0.079447    0.478759     0.999195\n",
       "3   9.105357    0.080298    0.466759     0.998793\n",
       "4   9.683739    0.080029    0.487214     0.998927"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model: Random Forest\n",
    "\n",
    "pipe_rf = make_pipeline(preprocessor_X, RandomForestClassifier(random_state=76))\n",
    "rfScores = cross_validate(pipe_rf, X_train, y_train, scoring=SCORING, return_train_score=True)\n",
    "print(\"Mean validation score %0.3f\" % (np.mean(rfScores[\"test_score\"])))\n",
    "print(\"Mean training score %0.3f\" % (np.mean(rfScores[\"train_score\"])))\n",
    "pd.DataFrame(rfScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean validation score 0.434\n",
      "Mean training score 0.573\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.036321</td>\n",
       "      <td>1.034258</td>\n",
       "      <td>0.437831</td>\n",
       "      <td>0.565995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.032621</td>\n",
       "      <td>0.122775</td>\n",
       "      <td>0.434505</td>\n",
       "      <td>0.573618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.028896</td>\n",
       "      <td>0.106882</td>\n",
       "      <td>0.433530</td>\n",
       "      <td>0.579512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.028589</td>\n",
       "      <td>0.109999</td>\n",
       "      <td>0.424603</td>\n",
       "      <td>0.575915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.037284</td>\n",
       "      <td>0.126586</td>\n",
       "      <td>0.437746</td>\n",
       "      <td>0.569481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  0.036321    1.034258    0.437831     0.565995\n",
       "1  0.032621    0.122775    0.434505     0.573618\n",
       "2  0.028896    0.106882    0.433530     0.579512\n",
       "3  0.028589    0.109999    0.424603     0.575915\n",
       "4  0.037284    0.126586    0.437746     0.569481"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model: KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "pipe_knn = make_pipeline(preprocessor_X, KNeighborsClassifier())\n",
    "knnScores = cross_validate(pipe_knn, X_train, y_train, scoring=SCORING, return_train_score=True)\n",
    "print(\"Mean validation score %0.3f\" % (np.mean(knnScores[\"test_score\"])))\n",
    "print(\"Mean training score %0.3f\" % (np.mean(knnScores[\"train_score\"])))\n",
    "pd.DataFrame(knnScores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SVM`: second-best cv test score with barely any overfitting.\n",
    "\n",
    "`Random Forest`: severely overfitting, but is giving the best cv test score. Need to see its performance on test set.\n",
    "\n",
    "`KNN`: worst cv test score with moderate overfitting.\n",
    "\n",
    "All three models beat the linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 8. Hyperparameter optimization <a name=\"10\"></a>\n",
    "<hr>\n",
    "\n",
    "_points: 10_\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Make some attempts to optimize hyperparameters for the models you've tried and summarize your results. In at least one case you should be optimizing multiple hyperparameters for a single model. You may use `sklearn`'s methods for hyperparameter optimization or fancier Bayesian optimization methods. \n",
    "  - [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)   \n",
    "  - [RandomizedSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "  - [scikit-optimize](https://github.com/scikit-optimize/scikit-optimize) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_8\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the logistic regression model, the best C hyperparameter is 10, with a best score of 0.358"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameter values:  {'logisticregression__C': 10.0}\n",
      "Best score: 0.358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wsr20\\anaconda3\\envs\\cpsc330\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#logistic regression\n",
    "\n",
    "param_grid = {\"logisticregression__C\": 10.0 ** np.arange(-4, 6, 1)}\n",
    "\n",
    "lr_search_multi = GridSearchCV(\n",
    "    pipe_lr,\n",
    "    param_grid,\n",
    "    scoring=SCORING,\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "lr_search_multi.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best hyperparameter values: \", lr_search_multi.best_params_)\n",
    "print(\"Best score: %0.3f\" % (lr_search_multi.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameter values:  {'svc__C': 10.0}\n",
      "Best score: 0.462\n"
     ]
    }
   ],
   "source": [
    "#svm model\n",
    "\n",
    "param_grid = {\n",
    "    \"svc__C\": 10.0 ** np.arange(-2, 4, 1)\n",
    "}\n",
    "\n",
    "svm_search_multi = GridSearchCV(\n",
    "    pipe_svm,\n",
    "    param_grid,\n",
    "    scoring=SCORING,\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "svm_search_multi.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best hyperparameter values: \", svm_search_multi.best_params_)\n",
    "print(\"Best score: %0.3f\" % (svm_search_multi.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For SVM, the best C is 10, with a a best score of 0.462. We only perform hyperparameter tuning for C because SVM takes too long to fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameter values:  {'kneighborsclassifier__n_neighbors': 41}\n",
      "Best score: 0.453\n"
     ]
    }
   ],
   "source": [
    "#knn model\n",
    "\n",
    "param_grid = {\"kneighborsclassifier__n_neighbors\": np.arange(1, 50, 5)}\n",
    "\n",
    "knn_search_multi = GridSearchCV(\n",
    "    pipe_knn,\n",
    "    param_grid,\n",
    "    scoring=SCORING,\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "knn_search_multi.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best hyperparameter values: \", knn_search_multi.best_params_)\n",
    "print(\"Best score: %0.3f\" % (knn_search_multi.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For KNN, the best n_neighbors is 41, with a best score of 0.453"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameter values:  {'randomforestclassifier__max_depth': None, 'randomforestclassifier__n_estimators': 300}\n",
      "Best score: 0.485\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "\n",
    "param_grid = {\n",
    "    'randomforestclassifier__n_estimators': [100, 200, 300],\n",
    "    'randomforestclassifier__max_depth': [None, 10, 20]\n",
    "}\n",
    "\n",
    "forest_search_multi = GridSearchCV(\n",
    "    pipe_rf,\n",
    "    param_grid,\n",
    "    scoring=SCORING,\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "forest_search_multi.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best hyperparameter values: \", forest_search_multi.best_params_)\n",
    "print(\"Best score: %0.3f\" % (forest_search_multi.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Random Forest, the best n_extimators is 300 and max_depth is None (default) with a score of 0.485. Random Forest is also slow in terms of training, so we only do tuning for a small range of hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 9. Results on the test set <a name=\"12\"></a>\n",
    "<hr>\n",
    "\n",
    "_points: 10_\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Try your best performing model on the test data: report and explain test scores.\n",
    "2. Do the test scores agree with the validation scores from before? To what extent do you trust your results? Do you think you've had issues with optimization bias?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_9\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model is Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = make_pipeline(preprocessor_X, RandomForestClassifier(n_estimators=300))\n",
    "best.fit(X_train, y_train)\n",
    "pred = best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4725658103393593"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 10. Summary of results <a name=\"13\"></a>\n",
    "<hr>\n",
    "\n",
    "_points 12_\n",
    "\n",
    "Imagine that you want to present the summary of these results to your boss and co-workers. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Create a table (printed `DataFrame`) summarizing important results. \n",
    "2. Write concluding remarks.\n",
    "3. Discuss other ideas that you did not try but could potentially improve the performance/interpretability . \n",
    "3. Report your final test score along with the metric you used at the top of this notebook in the [Submission instructions section](#si)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_10\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PLEASE READ:** When you are ready to submit your assignment do the following:\n",
    "\n",
    "1. Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`. \n",
    "2. Notebooks with cell execution numbers out of order or not starting from “1” will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "3. Upload the assignment using [PrairieLearn](https://ca.prairielearn.com/pl/course_instance/6697). Don't forget to rename your file `hw4_sol.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a tricky one but you did it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/eva-well-done.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpsc330",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
